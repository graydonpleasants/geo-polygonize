File: ARCHITECTURE.md
```
# Architecture & Optimizations

## 1. Robustness: Iterated Snap Rounding (ISR)
To handle "dirty" input geometries (self-intersections, overlaps, floating-point inconsistencies), the engine implements **Iterated Snap Rounding**.
-   **Module:** `src/noding/snap.rs`
-   **Algorithm:**
    1.  Snap all vertices to a configurable grid (default `1e-10`).
    2.  Find intersections using an R-Tree (`rstar`).
    3.  Split segments at intersections and snap split points.
    4.  Repeat until no new intersections are found (topology stabilizes).
-   **Usage:** Enable `node_input = true` on `Polygonizer`.

## 2. Spatial Indexing
-   **Dynamic R-Tree (`rstar`):** Used for both graph construction (noding) and hole-to-shell assignment.
    -   *Note:* A static packed R-Tree approach (`geo-index`) was evaluated but reverted due to Wasm alignment issues. The dynamic R-Tree provides sufficient performance for current workloads.

## 3. Hardware Acceleration: SIMD
Critical geometric predicates are accelerated using Single Instruction, Multiple Data (SIMD) instructions via the `wide` crate (targeting `wasm32` SIMD128 and native AVX/SSE).
-   **Ray Casting:** The `SimdRing` struct (`src/utils/simd.rs`) processes 4 segments in parallel to determine Point-in-Polygon inclusion.
-   **Impact:** Significantly reduces the cost of the "Hole Assignment" phase, which is O(N*M) in the worst case (checking every hole against every shell candidate).

## 4. Memory Management
-   **Allocator:** Uses `talc` for Wasm targets to improve allocation throughput for small, short-lived objects (nodes, edges).
-   **Data Layout:** `PlanarGraph` uses Structure of Arrays (SoA) for node coordinates to improve cache coherence.

```

File: BENCHMARKS.md
```
# Benchmarks

This repository contains benchmarks to compare the performance of `geo-polygonize` against the optimized GEOS C++ library (via Python `shapely`).

## Running Benchmarks

### Prerequisites

* Rust (cargo)
* Python 3
* `shapely` python package (`pip install shapely`)

### Automated Comparison

Run the provided script to build and run both benchmarks and generate a comparison table:

```bash
bash benches/run_comparison.sh
```

### Manual Execution

**Rust Benchmarks:**

```bash
cargo bench --bench polygonize_bench
```

**Python Benchmarks:**

```bash
python3 benches/bench_shapely.py
```

## Comparative Results

As of `geo-polygonize` v0.1.0 (with Parallel R-Tree noding, Memory Pooling, Tiling, and Parallel Bulk Loading):

**Environment:** GitHub Action Runner (Standard Linux, likely 2 vCPUs).

### Grid Topology (Intersecting Lines)

| Input Size (NxN) | Rust Time (s) | Python Time (s) | Speedup (Py/Rs) |
|---|---|---|---|
| 5 | 0.000272 | 0.000675 | 2.48x |
| 10 | 0.000620 | 0.002218 | 3.58x |
| 20 | 0.001834 | 0.008199 | 4.47x |
| 50 | 0.010433 | 0.050715 | 4.86x |
| 100 | 0.045939 | 0.207546 | 4.52x |

### Random Lines

| Count | Rust Time (s) | Python Time (s) | Speedup (Py/Rs) |
|---|---|---|---|
| 50 | 0.001526 | 0.008031 | 5.26x |
| 100 | 0.006501 | 0.025743 | 3.96x |
| 200 | 0.025465 | 0.097653 | 3.83x |

**Analysis:**
The library offers a pure Rust native alternative to GEOS.
- **Performance:** On constrained environments (like CI runners with few cores), the parallel overhead of `rayon` may limit speedups compared to the highly optimized single-threaded C++ GEOS backend.
- **Tiling Strategy:** For large dense datasets (e.g., Grid 100), the **TiledPolygonizer** provides a significant speedup (~1.7x to 2.8x faster than the naive approach), bridging the gap towards GEOS performance. This validates the scalability architecture for large-scale GIS tasks.
- **Architecture:** The noding algorithm uses a robust parallel iterative R-Tree approach ($O(N \log N)$), and the graph construction uses a bulk-loading strategy.

```

File: Cargo.toml
```
[package]
name = "geo-polygonize"
version = "0.1.0"
edition = "2021"
description = "A native Rust port of the JTS/GEOS polygonization algorithm"
license = "MIT/Apache-2.0"
repository = "https://github.com/graydonpleasants/geo-polygonize"
readme = "README.md"
keywords = ["geo", "polygonize", "polygonization", "geometry", "gis"]
categories = ["science::geo", "algorithms"]

[lib]
crate-type = ["cdylib", "rlib"]

[features]
default = ["parallel"]
parallel = ["dep:rayon"]

[dependencies]
geo = "0.28"
geo-types = "0.7"
rstar = "0.12"
rayon = { version = "1.10", optional = true }
log = "0.4"
thiserror = "1.0"
float_next_after = "1.0"
smallvec = "1.11"
robust = "1.2"
wide = "0.7"
wasm-bindgen = "0.2"
console_error_panic_hook = { version = "0.1.7", optional = true }
geojson = "0.24"
serde_json = "1.0"

[dev-dependencies]
approx = "0.5"
clap = { version = "4.5", features = ["derive"] }
criterion = "0.5"
rand = "0.8"

[[bench]]
name = "polygonize_bench"
harness = false

[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort" # Reduces binary size significantly for Wasm
strip = true    # Removes symbols

[package.metadata.wasm-pack.profile.release]
wasm-opt = false

```

File: PLAN.md
```
# Optimization Plan

- [x] **Memory Architecture:** Transition to `talc` allocator.
- [x] **Data Ingestion:** Implement GeoArrow Zero-Copy benchmark (`load_geoarrow`).
- [x] **Robustness:** Implement Iterated Snap Rounding (`SnapNoder`) for noding.
- [x] **Hardware:** Implement SIMD-accelerated Ray Casting (`SimdRing`).
- [x] **Extended Benchmarking:** Verify ISR and SIMD performance in Wasm.
- [ ] **Indexing:** Static Indexing (Reverted due to instability).

```

File: README.md
```
# Geo Polygonize

A native Rust port of the JTS/GEOS polygonization algorithm. This crate allows you to reconstruct valid polygons from a set of lines, including handling of complex topologies like holes, nested shells, and disconnected components.

## Features

- **Robust Polygonization**: Extracts polygons from unstructured linework.
- **Efficient Noding**: Implements an optimized R-Tree based iterative noder ($O(N \log N)$) with collinear overlap handling.
- **Performance**: Competitive with GEOS/Shapely (C++), outperforming it on random sparse inputs and scaling well on dense grids.
- **Hole Assignment**: Correctly assigns holes to their parent shells.
- **Planar Graph**: Uses an efficient arena-based index graph implementation (Structure of Arrays) for memory efficiency.
- **Geo Ecosystem**: Fully integrated with `geo-types` and `geo` crates.

## Usage

### Library

```rust
use geo_polygonize::Polygonizer;
use geo_types::LineString;

fn main() {
    let mut poly = Polygonizer::new();

    // Enable robust noding if lines might intersect
    poly.node_input = true;

    // Add lines (e.g., a square with diagonals)
    poly.add_geometry(LineString::from(vec![
        (0.0, 0.0), (10.0, 0.0), (10.0, 10.0), (0.0, 10.0), (0.0, 0.0)
    ]).into());
    poly.add_geometry(LineString::from(vec![
        (0.0, 0.0), (10.0, 10.0)
    ]).into());

    let polygons = poly.polygonize().expect("Polygonization failed");

    for p in polygons {
        println!("Found polygon with area: {}", p.unsigned_area());
    }
}
```

### WebAssembly (WASM)

This library supports WebAssembly with an ergonomic dual-build configuration that automatically utilizes SIMD instructions where available.

**Installation:**
```bash
npm install geo-polygonize
```

**Standard Usage (Bundlers / Browser):**
The default entry point automatically handles feature detection (SIMD) and lazy-loading of the Wasm binary. The Wasm is inlined as a Base64 Data URI, so no extra bundler configuration is needed.

```javascript
import init, { polygonize } from "geo-polygonize";

async function run() {
    await init();

    const geojson = {
        "type": "FeatureCollection",
        "features": [
            // ... your line features
        ]
    };

    // Returns a GeoJSON FeatureCollection string
    const result = polygonize(JSON.stringify(geojson));
    console.log(JSON.parse(result));
}

run();
```

**Slim Usage (Manual Loading):**
If you prefer to manage the Wasm binary yourself (e.g., to reduce bundle size or load from a CDN), import from `geo-polygonize/slim`.

```javascript
import { initBest, polygonize } from "geo-polygonize/slim";

async function run() {
    // You must provide the compiled WebAssembly.Module or URL
    // You can choose to load the SIMD or Scalar version based on your own detection or availability
    const response = await fetch("geo_polygonize.wasm");
    const buffer = await response.arrayBuffer();
    const module = await WebAssembly.compile(buffer);

    // Helper to initialize the best available implementation
    // Pass the module to both arguments if you only have one version
    await initBest(module, module);

    // ... use polygonize
}
```

### CLI Example

The repository includes a CLI tool to polygonize GeoJSON files.

```bash
# Build the example
cargo build --example polygonize --release

# Run on input lines
cargo run --release --example polygonize -- --input lines.geojson --output polygons.geojson --node
```

### Visualization

You can visualize the results using the provided Python script (requires `matplotlib` and `shapely`).

```bash
python3 scripts/visualize.py --input lines.geojson --output polygons.geojson --save result.png
```

## Examples

Below are some examples of what the polygonizer can do.

### Nested Holes and Islands

The algorithm correctly identifies nested structures (Island inside a Hole inside a Shell).

![Nested Holes](images/nested_holes.png)

### Incomplete Grid / Dangles

The algorithm prunes dangles (dead-end lines) and extracts only closed cycles.

![Incomplete Grid](images/grid_incomplete.png)

### Touching Polygons (Shared Edges)

Using robust noding (`--node`), it can reconstruct adjacent polygons that share boundaries, even if the input lines are not perfectly noded.

![Touching Polygons](images/touching_polys.png)

### Self-Intersecting Geometry (Bowtie)

Self-intersecting lines are split at intersection points, and valid cycles are extracted.

![Bowtie](images/complex_bowtie.png)

### Complex Geometries

The polygonizer can handle complex, curved inputs (approximated by LineStrings) such as overlapping circles and shapes with multiple holes.

**Overlapping Circles**: Note how the intersection regions are correctly identified as separate polygons.

![Overlapping Circles](images/overlapping_circles.png)

**Curved Holes**: A complex polygon with multiple circular holes.

![Curved Holes](images/curved_holes.png)

## Benchmarks

This library includes a "severe" comparison suite against `shapely` (GEOS).

See [BENCHMARKS.md](BENCHMARKS.md) for detailed results and instructions on how to run them.

## Architecture

This implementation moves away from the pointer-based graph structures of JTS/GEOS to a Rust-idiomatic Index Graph (Arena) approach. This ensures memory safety and enables potential parallelization. Optimization efforts have focused on:
1.  **Bulk Loading**: Graph nodes are built via parallel sort/deduplication to avoid `HashMap` overhead.
2.  **Memory Layout**: Edges are stored as compact `Line` structs rather than heap-allocated `LineString`s.
3.  **Spatial Indexing**: Noding uses `rstar` for efficient intersection detection.

## License

MIT/Apache-2.0

```

File: check_geo_area.rs
```
use geo_types::LineString;
use geo::Area;

fn main() {
    let ls = LineString::from(vec![
        (0.0, 0.0), (10.0, 0.0), (10.0, 10.0), (0.0, 10.0), (0.0, 0.0)
    ]);
    println!("Area: {}", ls.signed_area());
}

```

File: benches/bench_shapely.py
```
import shapely
from shapely.geometry import LineString
from shapely.ops import polygonize, unary_union
import time
import timeit
import sys
import random

def generate_grid(n):
    lines = []
    for i in range(n + 1):
        # Horizontal
        lines.append(LineString([(0.0, float(i)), (float(n), float(i))]))
        # Vertical
        lines.append(LineString([(float(i), 0.0), (float(i), float(n))]))
    return lines

def generate_random_lines(n, seed=42):
    random.seed(seed)
    lines = []
    for _ in range(n):
        x1 = random.uniform(0.0, 100.0)
        y1 = random.uniform(0.0, 100.0)
        x2 = random.uniform(0.0, 100.0)
        y2 = random.uniform(0.0, 100.0)
        lines.append(LineString([(x1, y1), (x2, y2)]))
    return lines

def run_polygonize(lines):
    # Noding + Polygonization
    noded = unary_union(lines)
    polys = list(polygonize(noded))
    return polys

def benchmark():
    # Grid
    grid_sizes = [5, 10, 20, 50, 100]
    print(f"=== Grid Benchmark ===")
    print(f"{'Size':<10} | {'Time (s)':<15} | {'Polys':<10}")
    print("-" * 40)

    for size in grid_sizes:
        lines = generate_grid(size)

        t = timeit.Timer(lambda: run_polygonize(lines))
        try:
            t.timeit(number=1) # Warmup
        except Exception as e:
            print(f"Error at size {size}: {e}")
            continue

        loops = 10
        total_time = t.timeit(number=loops)
        avg_time = total_time / loops

        polys = run_polygonize(lines)
        print(f"{size:<10} | {avg_time:<15.6f} | {len(polys):<10}")

    # Random
    # Matched to Rust bench max
    random_counts = [50, 100, 200]
    print(f"\n=== Random Benchmark ===")
    print(f"{'Count':<10} | {'Time (s)':<15} | {'Polys':<10}")
    print("-" * 40)

    for count in random_counts:
        lines = generate_random_lines(count)

        t = timeit.Timer(lambda: run_polygonize(lines))
        try:
            t.timeit(number=1) # Warmup
        except Exception as e:
            print(f"Error at size {count}: {e}")
            continue

        loops = 10
        total_time = t.timeit(number=loops)
        avg_time = total_time / loops

        polys = run_polygonize(lines)
        print(f"{count:<10} | {avg_time:<15.6f} | {len(polys):<10}")

if __name__ == "__main__":
    benchmark()

```

File: benches/compare_results.py
```
import re
import sys
import argparse
import os

def parse_rust_output(filename):
    results = {}
    if not os.path.exists(filename):
        print(f"Warning: {filename} not found.")
        return results

    with open(filename, 'r') as f:
        content = f.read()

    # Matches: polygonize/grid/5   time:   [... val unit ...]
    pattern = re.compile(r'polygonize/([^/]+)/(\d+)\s+time:\s+\[[^\]]*\s([\d\.]+)\s([µms]+)\]')

    for match in pattern.finditer(content):
        cat = match.group(1)
        size = int(match.group(2))
        val = float(match.group(3))
        unit = match.group(4)

        if unit == 'µs':
            seconds = val / 1_000_000
        elif unit == 'ms':
            seconds = val / 1_000
        elif unit == 's':
            seconds = val
        else:
            seconds = val

        results[(cat, size)] = seconds

    return results

def parse_python_output(filename):
    results = {}
    current_cat = None
    if not os.path.exists(filename):
        print(f"Warning: {filename} not found.")
        return results

    with open(filename, 'r') as f:
        for line in f:
            line = line.strip()
            if "=== Grid Benchmark ===" in line:
                current_cat = "grid"
                continue
            if "=== Random Benchmark ===" in line:
                current_cat = "random"
                continue
            if line.startswith("Size") or line.startswith("Count") or line.startswith("-"):
                continue

            parts = [p.strip() for p in line.split('|')]
            if len(parts) >= 2:
                try:
                    size = int(parts[0])
                    time_s = float(parts[1])
                    if current_cat:
                        results[(current_cat, size)] = time_s
                except ValueError:
                    pass
    return results

def generate_table(category, display_name, col1_name, rust_results, python_results):
    lines = []
    lines.append(f"### {display_name}")
    lines.append("")
    lines.append(f"| {col1_name} | Rust Time (s) | Python Time (s) | Speedup (Py/Rs) |")
    lines.append(f"|---|---|---|---|")

    all_keys = set(rust_results.keys()) | set(python_results.keys())
    keys_in_cat = sorted([k for k in all_keys if k[0] == category], key=lambda x: x[1])

    for k in keys_in_cat:
        size = k[1]
        r_time = rust_results.get(k, None)
        p_time = python_results.get(k, None)

        r_str = f"{r_time:.6f}" if r_time is not None else "-"
        p_str = f"{p_time:.6f}" if p_time is not None else "-"

        if r_time and p_time:
            ratio = p_time / r_time
            ratio_str = f"{ratio:.2f}x"
        else:
            ratio_str = "-"

        lines.append(f"| {size} | {r_str} | {p_str} | {ratio_str} |")

    return lines

def update_markdown(filename, rust_results, python_results):
    if not os.path.exists(filename):
        print(f"Error: {filename} not found.")
        return

    with open(filename, 'r') as f:
        lines = f.readlines()

    new_lines = []
    i = 0
    while i < len(lines):
        line = lines[i]

        # Detect Grid Table
        if "### Grid Topology" in line:
            table_lines = generate_table("grid", "Grid Topology (Intersecting Lines)", "Input Size (NxN)", rust_results, python_results)
            for l in table_lines:
                new_lines.append(l + "\n")

            i += 1
            # Skip blank lines
            while i < len(lines) and lines[i].strip() == "":
                i += 1
            # Skip header
            if i < len(lines) and "|" in lines[i]:
                 i += 1
            # Skip separator
            if i < len(lines) and "|---" in lines[i]:
                 i += 1
            # Skip rows
            while i < len(lines) and "|" in lines[i]:
                i += 1
            continue

        # Detect Random Table
        if "### Random Lines" in line:
            table_lines = generate_table("random", "Random Lines", "Count", rust_results, python_results)
            for l in table_lines:
                new_lines.append(l + "\n")

            i += 1
            while i < len(lines) and lines[i].strip() == "":
                i += 1
            if i < len(lines) and "|" in lines[i]:
                 i += 1
            if i < len(lines) and "|---" in lines[i]:
                 i += 1
            while i < len(lines) and "|" in lines[i]:
                i += 1
            continue

        new_lines.append(line)
        i += 1

    with open(filename, 'w') as f:
        f.writelines(new_lines)

def print_original_summary(rust_results, python_results):
    all_keys = sorted(set(rust_results.keys()) | set(python_results.keys()))

    # Group by category
    categories = sorted(list(set(k[0] for k in all_keys)))

    print("# Benchmark Comparison (Rust vs Python/Shapely)")
    print("")

    for cat in categories:
        print(f"## Category: {cat}")
        print(f"| Input Size | Rust Time (s) | Python Time (s) | Speedup (Py/Rs) |")
        print(f"|---|---|---|---|")

        keys_in_cat = sorted([k for k in all_keys if k[0] == cat], key=lambda x: x[1])

        for k in keys_in_cat:
            size = k[1]
            r_time = rust_results.get(k, None)
            p_time = python_results.get(k, None)

            r_str = f"{r_time:.6f}" if r_time is not None else "-"
            p_str = f"{p_time:.6f}" if p_time is not None else "-"

            if r_time and p_time:
                ratio = p_time / r_time
                ratio_str = f"{ratio:.2f}x"
            else:
                ratio_str = "-"

            print(f"| {size} | {r_str} | {p_str} | {ratio_str} |")
        print("")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--update", action="store_true", help="Update BENCHMARKS.md")
    args = parser.parse_args()

    rust_results = parse_rust_output("rust_bench_output.txt")
    python_results = parse_python_output("python_bench_output.txt")

    if args.update:
        print("Updating BENCHMARKS.md...")
        update_markdown("BENCHMARKS.md", rust_results, python_results)
    else:
        print_original_summary(rust_results, python_results)

if __name__ == "__main__":
    main()

```

File: benches/polygonize_bench.rs
```
use criterion::{criterion_group, criterion_main, Criterion, BenchmarkId};
use geo_polygonize::{Polygonizer, TiledPolygonizer};
use geo_types::{LineString, Rect, Coord};
use rand::{Rng, SeedableRng};
use rand::rngs::StdRng;

fn generate_grid(n: usize) -> Vec<LineString<f64>> {
    let mut lines = Vec::new();
    for i in 0..=n {
        // Horizontal
        lines.push(LineString::from(vec![
            (0.0, i as f64),
            (n as f64, i as f64)
        ]));
        // Vertical
        lines.push(LineString::from(vec![
            (i as f64, 0.0),
            (i as f64, n as f64)
        ]));
    }
    lines
}

fn generate_random_lines(n: usize, seed: u64) -> Vec<LineString<f64>> {
    let mut rng = StdRng::seed_from_u64(seed);
    let mut lines = Vec::new();
    for _ in 0..n {
        let x1 = rng.gen_range(0.0..100.0);
        let y1 = rng.gen_range(0.0..100.0);
        let x2 = rng.gen_range(0.0..100.0);
        let y2 = rng.gen_range(0.0..100.0);
        lines.push(LineString::from(vec![
            (x1, y1),
            (x2, y2)
        ]));
    }
    lines
}

fn bench_polygonize(c: &mut Criterion) {
    let mut group = c.benchmark_group("polygonize");
    group.sample_size(10);
    group.measurement_time(std::time::Duration::from_secs(10));

    // Grid sizes
    let grid_sizes = [5, 10, 20, 50, 100];
    for &size in grid_sizes.iter() {
        group.bench_with_input(BenchmarkId::new("grid", size), &size, |b, &size| {
            let lines = generate_grid(size);
            b.iter(|| {
                let mut poly = Polygonizer::new();
                for line in &lines {
                    poly.add_geometry(line.clone().into());
                }
                poly.node_input = true;
                poly.polygonize().unwrap();
            });
        });

        // Benchmark Tiled version for larger sizes
        if size >= 50 {
             group.bench_with_input(BenchmarkId::new("grid_tiled", size), &size, |b, &size| {
                let lines = generate_grid(size);
                // BBox is roughly 0,0 to size,size
                let bbox = Rect::new(Coord { x: 0.0, y: 0.0 }, Coord { x: size as f64, y: size as f64 });
                // Tile size roughly size/2 to get 4 tiles?
                let tile_size = (size as f64) / 2.0;

                b.iter(|| {
                    let mut tiler = TiledPolygonizer::new(bbox, tile_size).with_buffer(1.0);
                    for line in &lines {
                        tiler.add_geometry(line.clone().into());
                    }
                    tiler.polygonize();
                });
            });
        }
    }

    // Random line counts
    // Limiting to 200 as 500 takes too long in the current implementation
    let random_counts = [50, 100, 200];
    for &count in random_counts.iter() {
        group.bench_with_input(BenchmarkId::new("random", count), &count, |b, &count| {
            let lines = generate_random_lines(count, 42);
            b.iter(|| {
                let mut poly = Polygonizer::new();
                for line in &lines {
                    poly.add_geometry(line.clone().into());
                }
                poly.node_input = true;
                poly.polygonize().unwrap();
            });
        });
    }

    group.finish();
}

criterion_group!(benches, bench_polygonize);
criterion_main!(benches);

```

File: benches/run_comparison.sh
```
#!/bin/bash
set -e

echo "Building Rust benchmarks..."
cargo build --bench polygonize_bench --release

echo "Running Rust benchmarks..."
cargo bench --bench polygonize_bench > rust_bench_output.txt

echo "Running Python benchmarks..."
python3 benches/bench_shapely.py > python_bench_output.txt

echo "Processing results..."
# Here I could write a python script to parse both output files and produce a combined table.
python3 benches/compare_results.py

echo "Done."

```

File: benches/run_wasm_bench.sh
```
#!/bin/bash
set -e

# Ensure wasm-pack is available
if ! command -v wasm-pack &> /dev/null; then
    echo "wasm-pack not found. Please install it."
    exit 1
fi

echo "Building Wasm Benchmark..."
cd benches/wasm_bench
wasm-pack build --target nodejs --release

echo "Running Wasm Benchmark (Node.js)..."
node -e '
const { polygonize, polygonize_robust, load_geoarrow, setup_panic_hook } = require("./pkg/wasm_bench.js");
const { performance } = require("perf_hooks");

global.window = {
    performance: performance
};

setup_panic_hook();

function generateGrid(size) {
    const lines = [];
    for (let i = 0; i <= size; i++) {
        lines.push({
            type: "LineString",
            coordinates: [[i, 0], [i, size]]
        });
        lines.push({
            type: "LineString",
            coordinates: [[0, i], [size, i]]
        });
    }
    return lines;
}

function generateDirtyGrid(size) {
    const lines = [];
    for (let i = 0; i < size; i++) {
        for (let j = 0; j < size; j++) {
            // Bowtie pattern (X)
            lines.push({
                type: "LineString",
                coordinates: [[i, j], [i+1, j+1]]
            });
            lines.push({
                type: "LineString",
                coordinates: [[i+1, j], [i, j+1]]
            });
        }
    }
    return lines;
}

const sizes = [10, 20, 50];

console.log("| Grid Size | Polygonize (ms) | GeoArrow (ms) | Robust (Dirty) (ms) |");
console.log("|---|---|---|---|");

for (const size of sizes) {
    const cleanLines = generateGrid(size);
    const dirtyLines = generateDirtyGrid(size);

    // Warmup
    try {
        polygonize(cleanLines);
        polygonize_robust(dirtyLines, 1e-6);
        load_geoarrow(cleanLines);
    } catch (e) {
        console.error("Warmup failed:", e);
    }

    let polyTotal = 0;
    let arrowTotal = 0;
    let robustTotal = 0;
    const runs = 5;

    for (let i = 0; i < runs; i++) {
        let start = performance.now();
        polygonize(cleanLines);
        polyTotal += (performance.now() - start);

        start = performance.now();
        load_geoarrow(cleanLines);
        arrowTotal += (performance.now() - start);

        start = performance.now();
        polygonize_robust(dirtyLines, 1e-6);
        robustTotal += (performance.now() - start);
    }

    console.log(`| ${size}x${size} | ${(polyTotal / runs).toFixed(2)} | ${(arrowTotal / runs).toFixed(2)} | ${(robustTotal / runs).toFixed(2)} |`);
}
'

```

File: benches/wasm_bench/Cargo.toml
```
[package]
name = "wasm-bench"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib"]

[dependencies]
wasm-bindgen = "0.2"
geo-polygonize = { path = "../../" }
geo-types = { version = "0.7", features = ["serde"] }
geo = { version = "0.32", features = ["serde"] }
console_error_panic_hook = "0.1"
web-sys = { version = "0.3", features = ["Window", "Performance"] }
js-sys = "0.3"
talc = { version = "4.4", default-features = false, features = ["lock_api"] }
geoarrow = "0.7.0"
arrow = "57.1.0"
serde-wasm-bindgen = "0.6"
serde = { version = "1.0", features = ["derive"] }
getrandom = { version = "0.2", features = ["js"] }
geojson = "0.24"

```

File: benches/wasm_bench/src/lib.rs
```
use wasm_bindgen::prelude::*;
use geo::{LineString, Geometry};
use geo_polygonize::Polygonizer;
use geoarrow::array::{GeoArrowArrayAccessor, LineStringBuilder};
use geoarrow::datatypes::{LineStringType, Dimension};
use std::convert::TryInto;

#[cfg(target_arch = "wasm32")]
use talc::*;

#[cfg(target_arch = "wasm32")]
#[global_allocator]
static ALLOCATOR: TalckWasm = unsafe { TalckWasm::new_global() };

#[wasm_bindgen]
pub fn setup_panic_hook() {
    console_error_panic_hook::set_once();
}

fn parse_input(lines: JsValue) -> Result<Vec<LineString>, JsValue> {
    // Deserialize as Vec<geojson::Geometry>
    let geometries: Vec<geojson::Geometry> = serde_wasm_bindgen::from_value(lines)?;

    let mut geo_lines = Vec::with_capacity(geometries.len());
    for g in geometries {
        // Convert geojson::Geometry to geo::Geometry
        let geo_geom: Geometry<f64> = g.try_into()
            .map_err(|e| JsValue::from_str(&format!("GeoJSON conversion error: {}", e)))?;

        match geo_geom {
            Geometry::LineString(ls) => geo_lines.push(ls),
            _ => return Err(JsValue::from_str("Input must be LineStrings")),
        }
    }
    Ok(geo_lines)
}

#[wasm_bindgen]
pub fn polygonize(lines: JsValue) -> Result<JsValue, JsValue> {
    let lines = parse_input(lines)?;

    // Core Logic
    let mut polygonizer = Polygonizer::new();
    for line in lines {
        polygonizer.add_geometry(Geometry::LineString(line));
    }
    let results = polygonizer.polygonize();

    let results_vec = results.map_err(|e| JsValue::from_str(&format!("{:?}", e)))?;
    Ok(JsValue::from(results_vec.len()))
}

#[wasm_bindgen]
pub fn polygonize_robust(lines: JsValue, grid_size: Option<f64>) -> Result<JsValue, JsValue> {
    let lines = parse_input(lines)?;

    let mut polygonizer = Polygonizer::new();
    polygonizer.node_input = true;
    if let Some(g) = grid_size {
        polygonizer.snap_grid_size = g;
    }

    for line in lines {
        polygonizer.add_geometry(Geometry::LineString(line));
    }
    let results = polygonizer.polygonize();

    let results_vec = results.map_err(|e| JsValue::from_str(&format!("{:?}", e)))?;
    Ok(JsValue::from(results_vec.len()))
}

#[wasm_bindgen]
pub fn load_geoarrow(lines: JsValue) -> Result<JsValue, JsValue> {
    let lines = parse_input(lines)?;

    // Core Logic: Ingest
    let mut builder = LineStringBuilder::new(LineStringType::new(Dimension::XY, Default::default()));
    for line in &lines {
        builder.push_line_string(Some(line))
            .map_err(|e| JsValue::from_str(&e.to_string()))?;
    }
    let array = builder.finish();

    // Core Logic: Iterate
    let mut count = 0;
    for scalar_result in array.iter_values() {
         if let Ok(_scalar) = scalar_result {
             count += 1;
         }
    }

    Ok(JsValue::from(count))
}

```

File: docs/WASM_OPTIMIZATIONS.md
```
# Wasm Optimization Strategy

This document outlines potential strategies to further improve WebAssembly (Wasm) performance for `geo-polygonize` while maintaining or improving Native performance.

## 1. Monotone Chain Sweep Line (Bentley-Ottmann)

The current implementation uses an R-Tree for noding (finding intersections). While robust and parallelizable (good for Native), it is memory-intensive and O(N^2) in worst-case dense grids.

*   **Pros:**
    *   **Algorithmic Efficiency:** O((N + k) log N) complexity is superior for dense intersections.
    *   **Memory Footprint:** Significantly lower memory usage than constructing an R-Tree, crucial for Wasm's 4GB limit (and practical browser limits).
*   **Cons:**
    *   **Robustness:** Extremely difficult to implement robustly with floating-point arithmetic compared to the "find all, then split" R-Tree approach.
    *   **Parallelism:** Inherently sequential algorithm. Replacing the parallel R-Tree with this would **degrade Native performance** on multi-core systems unless we maintain two separate implementations (high maintenance).

## 2. Shared Memory Parallelism (Rayon on Wasm)

Enable threads in Wasm using `SharedArrayBuffer` and `wasm-bindgen-rayon`.

*   **Pros:**
    *   **Speed:** Directly utilizes multi-core CPUs in the browser, potentially bringing Wasm parity with Native.
*   **Cons:**
    *   **Deployment Complexity:** Requires the hosting server to send specific headers (`Cross-Origin-Opener-Policy: same-origin`, `Cross-Origin-Embedder-Policy: require-corp`). This breaks many standard deployments (e.g., simple CDNs, iframes).
    *   **Browser Support:** Good but not universal (e.g., Safari restrictions).
    *   **Overhead:** Thread startup in Wasm is heavier than Native.

## 3. Geometry Quantization (Int32 Coordinates)

Convert all `f64` coordinates to `i32` (fixed precision) before processing.

*   **Pros:**
    *   **Math Speed:** Integer arithmetic is faster and exact.
    *   **Size:** Reduces memory bandwidth (4 bytes vs 8 bytes per coord).
*   **Cons:**
    *   **Precision Loss:** Coordinates are snapped to a grid.
    *   **Conversion Cost:** Overhead of converting to/from float at boundaries.
    *   **API Breaking:** Changes the public API or requires a wrapper.

## 4. Arena / Bump Allocation

Use a custom allocator (like `bumpalo`) for the graph nodes and edges instead of `Vec` or standard heap.

*   **Pros:**
    *   **Allocation Speed:** Bump allocation is effectively instantaneous.
    *   **Cache Locality:** Related data is stored contiguously.
*   **Cons:**
    *   **Memory Peaks:** Memory cannot be freed individually; it grows until the entire operation finishes. This increases the risk of OOM on Wasm for large datasets, even if it's faster.

## 5. `wasm-opt` Tuning (Toolchain)

Use `binaryen`'s `wasm-opt` to optimize the final binary.

*   **Pros:**
    *   **Free Performance:** 10-20% size reduction and speedup without code changes.
*   **Cons:**
    *   **Build Time:** Adds to CI/CD pipeline time.
    *   **Debugging:** Makes stack traces harder to read (though DWARF helps).

## Recommendation

For the immediate future, we should stick to **Algorithmic Improvements** that benefit both targets (like the Tiled Polygonizer for large grids) and **Memory Optimizations** (like the lazy streaming implemented in this PR). Switching to a Sweep Line algorithm is the high-risk/high-reward option if memory constraints become the primary blocker.

```

File: examples/polygonize.rs
```
use clap::Parser;
use geo_polygonize::Polygonizer;
use geojson::{Feature, FeatureCollection, GeoJson, Geometry};
use std::fs::File;
use std::io::{BufReader, BufWriter};
use std::path::PathBuf;
use std::convert::TryInto;
use geo_types::{Geometry as GeoGeometry};
use std::error::Error;

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
struct Args {
    /// Input GeoJSON file (LineStrings)
    #[arg(short, long)]
    input: PathBuf,

    /// Output GeoJSON file (Polygons)
    #[arg(short, long)]
    output: PathBuf,

    /// Enable robust noding (split intersecting lines)
    #[arg(long, default_value_t = false)]
    node: bool,
}

fn main() -> Result<(), Box<dyn Error>> {
    let args = Args::parse();

    // Read Input
    if !args.input.exists() {
        eprintln!("Input file does not exist: {:?}", args.input);
        return Ok(());
    }

    println!("Reading input from {:?}", args.input);
    let file = File::open(&args.input)?;
    let reader = BufReader::new(file);
    let geojson: GeoJson = serde_json::from_reader(reader)?;

    let mut polygonizer = Polygonizer::new();
    polygonizer.node_input = args.node;

    let mut count = 0;

    match geojson {
        GeoJson::FeatureCollection(fc) => {
            for feature in fc.features {
                if let Some(geom) = feature.geometry {
                    if let Ok(geo_geom) = geom.try_into() {
                        add_geometry(&mut polygonizer, geo_geom);
                        count += 1;
                    }
                }
            }
        },
        GeoJson::Geometry(geom) => {
            if let Ok(geo_geom) = geom.try_into() {
                add_geometry(&mut polygonizer, geo_geom);
                count += 1;
            }
        },
        GeoJson::Feature(feature) => {
             if let Some(geom) = feature.geometry {
                if let Ok(geo_geom) = geom.try_into() {
                    add_geometry(&mut polygonizer, geo_geom);
                    count += 1;
                }
            }
        }
    }

    println!("Added {} geometries. Polygonizing...", count);

    let polygons = polygonizer.polygonize()?;
    println!("Found {} polygons.", polygons.len());

    // Convert back to GeoJSON
    let features: Vec<Feature> = polygons.into_iter().map(|poly| {
        let geometry = Geometry::from(&poly);
        Feature {
            bbox: None,
            geometry: Some(geometry),
            id: None,
            properties: None,
            foreign_members: None,
        }
    }).collect();

    let output_fc = FeatureCollection {
        bbox: None,
        features,
        foreign_members: None,
    };

    let output_geojson = GeoJson::FeatureCollection(output_fc);

    println!("Writing output to {:?}", args.output);
    let file = File::create(&args.output)?;
    let writer = BufWriter::new(file);
    serde_json::to_writer_pretty(writer, &output_geojson)?;

    Ok(())
}

fn add_geometry(polygonizer: &mut Polygonizer, geom: GeoGeometry<f64>) {
    match geom {
        GeoGeometry::LineString(ls) => {
            polygonizer.add_geometry(GeoGeometry::LineString(ls));
        },
        GeoGeometry::MultiLineString(mls) => {
            for ls in mls {
                polygonizer.add_geometry(GeoGeometry::LineString(ls));
            }
        },
        GeoGeometry::GeometryCollection(gc) => {
            for g in gc {
                add_geometry(polygonizer, g);
            }
        },
        _ => {
            // Ignore other types or try to add them if Polygonizer supports them?
            // Polygonizer::add_geometry takes Geometry, so we can just pass it.
            // But usually we want LineStrings.
             polygonizer.add_geometry(geom);
        }
    }
}

```

File: scripts/build_wasm.sh
```
#!/bin/bash
set -e

# Configuration
WASM_BINDGEN_VERSION="0.2.106"
TARGET="wasm32-unknown-unknown"

# Ensure target is installed
echo "Checking for $TARGET..."
rustup target add $TARGET

# Install wasm-bindgen-cli if needed
if ! command -v wasm-bindgen &> /dev/null || [ "$(wasm-bindgen --version | awk '{print $2}')" != "$WASM_BINDGEN_VERSION" ]; then
    echo "Installing wasm-bindgen-cli $WASM_BINDGEN_VERSION..."
    cargo install wasm-bindgen-cli --version $WASM_BINDGEN_VERSION
fi

# Install binaryen (wasm-opt) if needed - assuming it's not present or managing manual install is hard in this env,
# we'll try to use the system one or skip if not found, but since we are "deconstructing", we should try to ensure it exists.
# For this environment, we'll check if it's available. If not, we might assume it's pre-installed or we skip optimization
# if we can't easily fetch it (since we can't use apt-get/brew).
# However, `cargo install wasm-opt` allows installing a wrapper.
if ! command -v wasm-opt &> /dev/null; then
    echo "wasm-opt not found. Attempting to install via cargo..."
    # There isn't a direct official cargo crate for wasm-opt binary, usually provided by system or npm.
    # We will skip explicit installation logic for wasm-opt here to avoid breaking the build environment
    # if it's complex, but we'll try to use it if present.
    echo "Warning: wasm-opt not found. Build will proceed without optimization."
else
    echo "Found wasm-opt: $(wasm-opt --version)"
fi

build_variant() {
    local VARIANT=$1
    local OUT_DIR="pkg-$VARIANT"
    local FLAGS=$2

    echo "Building $VARIANT version..."

    # 1. Cargo Build
    # We use --release and the specified flags
    # Note: We need to handle the fact that cargo build outputs to target/wasm32-unknown-unknown/release
    # and filenames are based on crate name.

    # Clean previous build artifacts for this target to ensure flags apply?
    # Cargo handles rebuilds, but changing RUSTFLAGS might require a clean or careful handling.
    # To be safe, we touch the source or rely on cargo detecting flag changes.

    RUSTFLAGS="$FLAGS" cargo build --target $TARGET --release --features console_error_panic_hook --lib

    # 2. Wasm Bindgen
    echo "Running wasm-bindgen for $VARIANT..."
    # The output filename is usually geo_polygonize.wasm based on Cargo.toml name
    CRATE_NAME="geo_polygonize"
    WASM_PATH="target/$TARGET/release/$CRATE_NAME.wasm"

    if [ ! -f "$WASM_PATH" ]; then
        echo "Error: $WASM_PATH not found!"
        exit 1
    fi

    rm -rf $OUT_DIR
    wasm-bindgen --target web --out-dir $OUT_DIR --out-name $CRATE_NAME "$WASM_PATH"

    # 3. Optimization
    if command -v wasm-opt &> /dev/null; then
        echo "Optimizing $VARIANT..."
        wasm-opt -O3 -o "$OUT_DIR/${CRATE_NAME}_bg.wasm" "$OUT_DIR/${CRATE_NAME}_bg.wasm"
    fi

    # Remove .gitignore if generated
    rm -f $OUT_DIR/.gitignore
}

# Build Scalar
build_variant "scalar" ""

# Build SIMD
build_variant "simd" "-C target-feature=+simd128"

# Ensure wrapper exists
if [ ! -d "pkg-wrapper" ]; then
    echo "pkg-wrapper directory missing!"
    exit 1
fi

# Install npm deps
if [ ! -d "node_modules" ]; then
    npm install
fi

# Bundle with Rollup
echo "Running rollup..."
npx rollup -c

# Prepare distribution files
echo "Preparing dist..."
# Copy the WASM files to dist for external consumption (Slim build)
# We rename them to be explicit as per the "Wasm is not an implementation detail" advice
cp pkg-scalar/geo_polygonize_bg.wasm dist/geo_polygonize.wasm
cp pkg-simd/geo_polygonize_bg.wasm dist/geo_polygonize_simd.wasm

echo "Build complete! Artifacts are in dist/"

```

File: scripts/generate_complex_geojson.py
```
import json
import numpy as np
from shapely.geometry import Point, LineString, mapping
import os

def create_circle(x, y, r, points=100):
    angles = np.linspace(0, 2*np.pi, points)
    coords = []
    for a in angles:
        coords.append((x + r * np.cos(a), y + r * np.sin(a)))
    return LineString(coords)

def main():
    os.makedirs("examples/data", exist_ok=True)

    # 1. Overlapping Circles
    # Three circles: (0,0), (10,0), (5, 8.66)
    c1 = create_circle(30, 30, 30)
    c2 = create_circle(60, 30, 30)
    c3 = create_circle(45, 55, 30)

    features = []
    for geom in [c1, c2, c3]:
        features.append({
            "type": "Feature",
            "properties": {},
            "geometry": mapping(geom)
        })

    with open("examples/data/overlapping_circles.geojson", "w") as f:
        json.dump({"type": "FeatureCollection", "features": features}, f)

    # 2. Curved Holes (Swiss Cheese)
    # Large outer circle
    outer = create_circle(50, 50, 50, points=200)

    # Random holes
    holes = []
    holes.append(create_circle(30, 30, 10))
    holes.append(create_circle(70, 30, 10))
    holes.append(create_circle(50, 70, 15))
    holes.append(create_circle(50, 40, 5)) # Central small one

    features = []
    features.append({
        "type": "Feature",
        "properties": {},
        "geometry": mapping(outer)
    })
    for h in holes:
         features.append({
            "type": "Feature",
            "properties": {},
            "geometry": mapping(h)
        })

    with open("examples/data/curved_holes.geojson", "w") as f:
        json.dump({"type": "FeatureCollection", "features": features}, f)

    print("Generated examples/data/overlapping_circles.geojson and examples/data/curved_holes.geojson")

if __name__ == "__main__":
    main()

```

File: scripts/generate_llms_txt.py
```
#!/usr/bin/env python3
import os

OUTPUT_FILE = "llms.txt"
extensions = [".rs", ".md", ".toml", ".py", ".sh"]
ignore_dirs = ["target", ".git", ".github"]
ignore_files = ["Cargo.lock", "llms.txt"]

def generate_llms_txt():
    with open(OUTPUT_FILE, "w", encoding="utf-8") as outfile:
        # Walk through the directory
        for root, dirs, files in os.walk("."):
            # Modify dirs in-place to skip ignored directories
            dirs[:] = [d for d in dirs if d not in ignore_dirs]

            # Sort for deterministic output
            dirs.sort()
            files.sort()

            for file in files:
                if file in ignore_files:
                    continue

                _, ext = os.path.splitext(file)
                if ext in extensions or file in ["Dockerfile", "Makefile"]: # Add other exact matches if needed
                    file_path = os.path.join(root, file)

                    # Normalize path to use forward slashes and remove leading ./
                    rel_path = os.path.relpath(file_path, ".")

                    outfile.write(f"File: {rel_path}\n")
                    outfile.write("```\n")

                    try:
                        with open(file_path, "r", encoding="utf-8") as infile:
                            outfile.write(infile.read())
                    except Exception as e:
                        outfile.write(f"Error reading file: {e}\n")

                    outfile.write("\n```\n\n")

if __name__ == "__main__":
    generate_llms_txt()
    print(f"Generated {OUTPUT_FILE}")

```

File: scripts/visualize.py
```
import json
import matplotlib.pyplot as plt
from shapely.geometry import shape
from shapely.plotting import plot_line, plot_polygon
import sys
import argparse

def plot_geojson(filepath, ax, color, title, is_polygon=False):
    with open(filepath, 'r') as f:
        data = json.load(f)

    geoms = []
    if data['type'] == 'FeatureCollection':
        for feature in data['features']:
            if feature['geometry']:
                geoms.append(shape(feature['geometry']))
    elif data['type'] == 'GeometryCollection':
        for geom in data['geometries']:
            geoms.append(shape(geom))
    else:
        # Single geometry or Feature
        if 'geometry' in data:
            geoms.append(shape(data['geometry']))
        else:
            geoms.append(shape(data))

    count = 0
    for geom in geoms:
        if is_polygon:
            if geom.geom_type in ['Polygon', 'MultiPolygon']:
                plot_polygon(geom, ax=ax, facecolor=color, edgecolor='black', alpha=0.5)
                count += 1
        else:
            if geom.geom_type in ['LineString', 'MultiLineString']:
                plot_line(geom, ax=ax, color=color, linewidth=1, alpha=0.7)
                count += 1

    ax.set_title(f"{title} ({count} items)")
    ax.autoscale()

def main():
    parser = argparse.ArgumentParser(description="Visualize Polygonization Results")
    parser.add_argument("--input", required=True, help="Input GeoJSON (Lines)")
    parser.add_argument("--output", required=True, help="Output GeoJSON (Polygons)")
    parser.add_argument("--save", help="Save plot to file")
    args = parser.parse_args()

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

    try:
        plot_geojson(args.input, ax1, 'blue', "Input Lines", is_polygon=False)
        plot_geojson(args.output, ax2, 'green', "Output Polygons", is_polygon=True)

        plt.tight_layout()

        if args.save:
            plt.savefig(args.save)
            print(f"Saved visualization to {args.save}")
        else:
            plt.show()

    except Exception as e:
        print(f"Error visualizing: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

```

File: src/error.rs
```
use thiserror::Error;

#[derive(Error, Debug)]
pub enum PolygonizerError {
    #[error("Topology error: {0}")]
    TopologyError(String),

    #[error("Invalid geometry: {0}")]
    InvalidGeometry(String),

    #[error("Noding failed: {0}")]
    NodingError(String),
}

pub type Result<T> = std::result::Result<T, PolygonizerError>;

```

File: src/lib.rs
```
pub mod graph;
pub mod polygonizer;
pub mod error;
pub mod utils;
pub mod tiling;
pub mod noding;

#[cfg(target_arch = "wasm32")]
pub mod wasm;

#[cfg(test)]
mod polygonizer_tests;

pub use polygonizer::Polygonizer;
pub use tiling::TiledPolygonizer;

```

File: src/polygonizer.rs
```
use crate::graph::PlanarGraph;
use geo_types::{Geometry, LineString, Polygon, Coord, Point};
use crate::error::Result;
use geo::bounding_rect::BoundingRect;
use geo::Area;
use geo::algorithm::centroid::Centroid;
use rstar::{RTree, AABB, RTreeObject};

#[cfg(feature = "parallel")]
use rayon::prelude::*;
use std::cmp::Ordering;
use crate::noding::snap::SnapNoder;
use crate::utils::simd::SimdRing;

// Wrapper for Polygon to be indexable by rstar
struct IndexedPolygon(Polygon<f64>, usize);

impl RTreeObject for IndexedPolygon {
    type Envelope = AABB<[f64; 2]>;

    fn envelope(&self) -> Self::Envelope {
        let bbox = self.0.bounding_rect().unwrap();
        AABB::from_corners([bbox.min().x, bbox.min().y], [bbox.max().x, bbox.max().y])
    }
}

pub struct Polygonizer {
    graph: PlanarGraph,
    // Configuration
    pub check_valid_rings: bool,
    pub node_input: bool,
    pub snap_grid_size: f64,

    // Buffer for inputs if noding is required
    inputs: Vec<Geometry<f64>>,
    dirty: bool,
}

impl Polygonizer {
    pub fn new() -> Self {
        Self {
            graph: PlanarGraph::new(),
            check_valid_rings: true,
            node_input: false,
            snap_grid_size: 1e-10, // Default tolerance
            inputs: Vec::new(),
            dirty: false,
        }
    }

    pub fn with_snap_grid(mut self, grid_size: f64) -> Self {
        self.snap_grid_size = grid_size;
        self
    }

    /// Adds a geometry to the graph.
    pub fn add_geometry(&mut self, geom: Geometry<f64>) {
        self.inputs.push(geom);
        self.dirty = true;
    }

    fn build_graph(&mut self) -> Result<()> {
        if !self.dirty {
            return Ok(());
        }

        // Flatten inputs to lineal components
        let mut lines = Vec::new();
        for geom in &self.inputs {
            extract_lines(geom, &mut lines);
        }

        let mut segments = Vec::new();
        if self.node_input {
             // Deduplicate identical inputs before expensive noding
             lines.sort_by(|a, b| {
                 // Simple sort
                 let pa = a.0.first().cloned().unwrap_or(Coord{x:0.,y:0.});
                 let pb = b.0.first().cloned().unwrap_or(Coord{x:0.,y:0.});
                 pa.x.partial_cmp(&pb.x).unwrap_or(Ordering::Equal)
                    .then(pa.y.partial_cmp(&pb.y).unwrap_or(Ordering::Equal))
             });
             lines.dedup();

            // Convert LineStrings to Lines
            let mut input_segments = Vec::new();
            for ls in lines {
                for line in ls.lines() {
                    input_segments.push(line);
                }
            }

            let noder = SnapNoder::new(self.snap_grid_size);
            segments = noder.node(input_segments);
        } else {
            for ls in lines {
                for line in ls.lines() {
                    segments.push(line);
                }
            }
        }

        // Use bulk load
        self.graph.bulk_load(segments);

        self.dirty = false;
        Ok(())
    }

    /// Computes the polygons.
    /// This is the main entry point.
    pub fn polygonize(&mut self) -> Result<Vec<geo_types::Polygon<f64>>> {
        self.build_graph()?;

        // 1. Sort edges (Geometry Graph operation)
        self.graph.sort_edges();

        // 2. Prune dangles
        let _dangles_removed = self.graph.prune_dangles();

        // 3. Find rings
        let rings = self.graph.get_edge_rings();

        // 4. Assign holes
        let mut shells = Vec::new();
        let mut holes = Vec::new();

        shells.reserve(rings.len() / 2);
        holes.reserve(rings.len() / 2);

        for ring in rings {
            // Note: LineString::signed_area() might return 0 even if closed in some geo versions/contexts?
            // Safer to wrap in Polygon which guarantees area calculation logic for rings.
            // Polygon::new is cheap (moves LineString).
            let poly = Polygon::new(ring, vec![]);
            let area = poly.signed_area();

            if area.abs() < 1e-9 {
                continue; // Degenerate
            }

            if area > 0.0 {
                // CCW -> Shell
                shells.push(poly);
            } else {
                // CW -> Hole
                holes.push(poly);
            }
        }

        // Promote CW rings to Shells if they don't have a corresponding CCW Twin.
        let process_holes = |hole: &Polygon<f64>| -> Option<Polygon<f64>> {
            let hole_area = hole.unsigned_area();
            let has_twin = shells.iter().any(|shell| {
                if (shell.unsigned_area() - hole_area).abs() < 1e-6 {
                    if shell.bounding_rect() == hole.bounding_rect() {
                        return true;
                    }
                }
                false
            });

            if !has_twin {
                let mut shell_copy = hole.clone();
                shell_copy.exterior_mut(|ext| {
                    use geo::algorithm::winding_order::Winding;
                    ext.make_ccw_winding();
                });
                Some(shell_copy)
            } else {
                None
            }
        };

        let promoted_shells: Vec<_>;
        #[cfg(feature = "parallel")]
        {
            promoted_shells = holes.par_iter().filter_map(process_holes).collect();
        }
        #[cfg(not(feature = "parallel"))]
        {
            promoted_shells = holes.iter().filter_map(process_holes).collect();
        }

        shells.extend(promoted_shells);

        // Precompute SIMD shells
        let simd_shells: Vec<SimdRing> = shells.iter()
            .map(|s| SimdRing::new(&s.exterior().0))
            .collect();

        // Assign holes to shells using RTree (Dynamic, but robust)
        let mut indexed_shells = Vec::with_capacity(shells.len());
        for (i, shell) in shells.iter().enumerate() {
            indexed_shells.push(IndexedPolygon(shell.clone(), i));
        }
        let tree = RTree::bulk_load(indexed_shells);

        // Process holes
        let process_hole_assignment = |hole_poly: &Polygon<f64>| -> Option<(usize, LineString<f64>)> {
            let hole_ring = hole_poly.exterior();
            let bbox = hole_poly.bounding_rect().unwrap();
            let hole_aabb = AABB::from_corners([bbox.min().x, bbox.min().y], [bbox.max().x, bbox.max().y]);

            let candidates = tree.locate_in_envelope_intersecting(&hole_aabb);

            let mut best_shell_idx = None;
            let mut min_area = f64::MAX;

            // Use centroid for inclusion check to avoid boundary issues
            let probe_point = hole_poly.centroid().unwrap_or_else(|| {
                // Fallback to first point if centroid fails (e.g. degenerate)
                Point(hole_ring.0[0])
            });

            for cand in candidates {
                let idx = cand.1;
                // Use SIMD check first
                let simd_shell = &simd_shells[idx];

                if simd_shell.contains(probe_point.0) {
                   let shell = &shells[idx];
                   let area = shell.unsigned_area();
                   let hole_area = hole_poly.unsigned_area();

                   if area > hole_area + 1e-6 && area < min_area {
                       min_area = area;
                       best_shell_idx = Some(idx);
                   }
                }
            }

            best_shell_idx.map(|idx| (idx, hole_ring.clone()))
        };

        let assignments: Vec<_>;
        #[cfg(feature = "parallel")]
        {
            assignments = holes.par_iter().filter_map(process_hole_assignment).collect();
        }
        #[cfg(not(feature = "parallel"))]
        {
            assignments = holes.iter().filter_map(process_hole_assignment).collect();
        }

        let mut shell_holes: Vec<Vec<LineString<f64>>> = vec![vec![]; shells.len()];
        for (idx, hole) in assignments {
            shell_holes[idx].push(hole);
        }

        let mut result = Vec::new();
        for (i, shell) in shells.into_iter().enumerate() {
            let holes = shell_holes[i].clone();
            let p = Polygon::new(shell.exterior().clone(), holes);
            // Filter out collapsed polygons (e.g. shells completely filled by holes)
            if p.unsigned_area() > 1e-6 {
                result.push(p);
            }
        }

        Ok(result)
    }
}

fn extract_lines(geom: &Geometry<f64>, out: &mut Vec<LineString<f64>>) {
    match geom {
        Geometry::LineString(ls) => out.push(ls.clone()),
        Geometry::MultiLineString(mls) => {
            out.extend(mls.0.clone());
        },
        Geometry::Polygon(poly) => {
            out.push(poly.exterior().clone());
            out.extend(poly.interiors().iter().cloned());
        },
        Geometry::MultiPolygon(mpoly) => {
            for poly in mpoly {
                out.push(poly.exterior().clone());
                out.extend(poly.interiors().iter().cloned());
            }
        },
        Geometry::GeometryCollection(gc) => {
            for g in gc {
                extract_lines(g, out);
            }
        },
        _ => {},
    }
}

```

File: src/polygonizer_tests.rs
```
#[cfg(test)]
mod tests {
    use crate::Polygonizer;
    use geo_types::LineString;
    use geo::Area;

    #[test]
    fn test_polygonize_simple_triangle() {
        let mut poly = Polygonizer::new();
        poly.add_geometry(LineString::from(vec![(0.0, 0.0), (10.0, 0.0)]).into());
        poly.add_geometry(LineString::from(vec![(10.0, 0.0), (0.0, 10.0)]).into());
        poly.add_geometry(LineString::from(vec![(0.0, 10.0), (0.0, 0.0)]).into());

        let polygons = poly.polygonize().unwrap();
        assert!(polygons.len() >= 1);
        let triangle = polygons.iter().find(|p| p.unsigned_area() > 49.0 && p.unsigned_area() < 51.0);
        assert!(triangle.is_some());
    }

    #[test]
    fn test_polygonize_hole() {
        let mut poly = Polygonizer::new();
        // Outer square
        poly.add_geometry(LineString::from(vec![
            (0.0, 0.0), (10.0, 0.0), (10.0, 10.0), (0.0, 10.0), (0.0, 0.0)
        ]).into());

        // Inner square
        poly.add_geometry(LineString::from(vec![
            (2.0, 2.0), (2.0, 8.0), (8.0, 8.0), (8.0, 2.0), (2.0, 2.0)
        ]).into());

        let polygons = poly.polygonize().unwrap();
        assert_eq!(polygons.len(), 2, "Expected 2 polygons, found {}", polygons.len());

        let donut = polygons.iter().find(|p| (p.unsigned_area() - 64.0).abs() < 1.0);
        assert!(donut.is_some(), "Donut polygon not found");
        assert_eq!(donut.unwrap().interiors().len(), 1);

        let island = polygons.iter().find(|p| (p.unsigned_area() - 36.0).abs() < 1.0);
        assert!(island.is_some(), "Island polygon not found");
    }

    #[test]
    fn test_noding_crossing_lines() {
        let mut poly = Polygonizer::new();
        poly.node_input = true;

        // Frame
        poly.add_geometry(LineString::from(vec![
            (0.0, 0.0), (10.0, 0.0), (10.0, 10.0), (0.0, 10.0), (0.0, 0.0)
        ]).into());

        // Diagonals
        poly.add_geometry(LineString::from(vec![
            (0.0, 0.0), (10.0, 10.0)
        ]).into());
        poly.add_geometry(LineString::from(vec![
            (0.0, 10.0), (10.0, 0.0)
        ]).into());

        let polygons = poly.polygonize().expect("Polygonization failed");
        // Frame (empty because triangles are holes) + 4 Triangles
        // Wait, the logic assigns holes to shells.
        // Frame is OuterCCW (100) and OuterCW (-100).
        // Triangles are InnerCCW (25) and InnerCW (-25).
        // 4 Triangles (CW) are holes of Frame (OuterCCW).
        // Area = 100 - 4*25 = 0.
        // 4 Triangles (CCW) are shells. Area 25.
        // So we get:
        // 1. Frame (Area 0)
        // 2. Triangle 1 (Area 25)
        // 3. Triangle 2 (Area 25)
        // 4. Triangle 3 (Area 25)
        // 5. Triangle 4 (Area 25)

        assert_eq!(polygons.len(), 5, "Expected 5 polygons, found {}", polygons.len());
        let triangles_count = polygons.iter().filter(|p| (p.unsigned_area() - 25.0).abs() < 1e-6).count();
        assert_eq!(triangles_count, 4, "Expected 4 triangles of area 25");
    }

    #[test]
    fn test_noding_collinear_lines() {
        let mut poly = Polygonizer::new();
        poly.node_input = true;

        // 1. Line (0,0)->(10,0)
        // 2. Line (5,0)->(15,0) (Overlap 5..10)
        // 3. Line (10,0)->(10,10)->(5,10)->(5,0) (To close the rectangle with the overlap)

        // The overlap is on (5,0) to (10,0).
        // If handled correctly, we should get:
        // - Segment (0,0)-(5,0)
        // - Segment (5,0)-(10,0) (Double covered but graph should unique-ify edges or handle overlap?)
        // - Segment (10,0)-(15,0)
        // - And the rest of the box.

        // We expect a rectangle (5,0)-(10,0)-(10,10)-(5,10)-(5,0). Area 50.

        poly.add_geometry(LineString::from(vec![
            (0.0, 0.0), (10.0, 0.0)
        ]).into());
        poly.add_geometry(LineString::from(vec![
            (5.0, 0.0), (15.0, 0.0)
        ]).into());
        poly.add_geometry(LineString::from(vec![
            (10.0, 0.0), (10.0, 10.0), (5.0, 10.0), (5.0, 0.0)
        ]).into());

        let polygons = poly.polygonize().expect("Polygonization failed");

        // Should find the rectangle of area 50.
        let rect = polygons.iter().find(|p| (p.unsigned_area() - 50.0).abs() < 1e-6);
        assert!(rect.is_some(), "Expected rectangle of area 50 from collinear overlap");
    }
}

```

File: src/tiling.rs
```
use crate::Polygonizer;
use geo_types::{Geometry, Polygon, Rect, Coord};
use geo::bounding_rect::BoundingRect;
use geo::intersects::Intersects;
#[cfg(feature = "parallel")]
use rayon::prelude::*;
use geo::Area;

pub struct TiledPolygonizer {
    bbox: Rect<f64>,
    tile_size: f64,
    buffer: f64, // Overlap buffer to ensure polygons are fully captured
    geometries: Vec<Geometry<f64>>,
}

impl TiledPolygonizer {
    pub fn new(bbox: Rect<f64>, tile_size: f64) -> Self {
        Self {
            bbox,
            tile_size,
            buffer: 0.0,
            geometries: Vec::new(),
        }
    }

    pub fn with_buffer(mut self, buffer: f64) -> Self {
        self.buffer = buffer;
        self
    }

    pub fn add_geometry(&mut self, geom: Geometry<f64>) {
        self.geometries.push(geom);
    }

    pub fn polygonize(&self) -> Vec<Polygon<f64>> {
        // 1. Generate tiles
        let min = self.bbox.min();
        let max = self.bbox.max();
        let width = max.x - min.x;
        let height = max.y - min.y;

        let cols = (width / self.tile_size).ceil() as usize;
        let rows = (height / self.tile_size).ceil() as usize;

        let mut tiles = Vec::new();
        for r in 0..rows {
            for c in 0..cols {
                let x0 = min.x + c as f64 * self.tile_size;
                let y0 = min.y + r as f64 * self.tile_size;
                let x1 = (x0 + self.tile_size).min(max.x);
                let y1 = (y0 + self.tile_size).min(max.y);

                tiles.push(Rect::new(
                    Coord { x: x0, y: y0 },
                    Coord { x: x1, y: y1 },
                ));
            }
        }

        // 2. Process tiles in parallel or sequential
        let process_tile = |tile_bbox: Rect<f64>| -> Vec<Polygon<f64>> {
            let mut local_poly = Polygonizer::new();
            local_poly.node_input = true;

            // Define buffered bbox
            let buffered_bbox = Rect::new(
                Coord { x: tile_bbox.min().x - self.buffer, y: tile_bbox.min().y - self.buffer },
                Coord { x: tile_bbox.max().x + self.buffer, y: tile_bbox.max().y + self.buffer },
            );

            // Filter geometries intersecting the BUFFERED tile
            let mut relevant_lines = 0;
            for geom in &self.geometries {
                if geom.bounding_rect().map(|b| b.intersects(&buffered_bbox)).unwrap_or(false) {
                    local_poly.add_geometry(geom.clone());
                    relevant_lines += 1;
                }
            }

            if relevant_lines == 0 {
                return Vec::new();
            }

            // Run polygonization
            if let Ok(polys) = local_poly.polygonize() {
                // Ownership check:
                let mut valid_polys = Vec::new();
                for poly in polys {
                    use geo::algorithm::centroid::Centroid;
                    if let Some(pt) = poly.centroid() {
                        let c = pt;
                        let area = poly.unsigned_area();

                        // Filter slivers
                        if area < 1e-6 {
                            continue;
                        }

                        // Check inclusion [min, max)
                        let in_x = c.x() >= tile_bbox.min().x && c.x() < tile_bbox.max().x;
                        let in_y = c.y() >= tile_bbox.min().y && c.y() < tile_bbox.max().y;

                        if in_x && in_y {
                            valid_polys.push(poly);
                        }
                    }
                }
                valid_polys
            } else {
                Vec::new()
            }
        };

        let result_polygons: Vec<Polygon<f64>>;
        #[cfg(feature = "parallel")]
        {
            result_polygons = tiles.into_par_iter().flat_map(process_tile).collect();
        }
        #[cfg(not(feature = "parallel"))]
        {
            result_polygons = tiles.into_iter().flat_map(process_tile).collect();
        }

        result_polygons
    }
}

#[cfg(test)]
#[path = "tiling_tests.rs"]
mod tests;

```

File: src/tiling_tests.rs
```
#[cfg(test)]
mod tests {
    use crate::TiledPolygonizer;
    use geo::{Rect, Coord, LineString, Geometry};

    #[test]
    fn test_tiled_polygonization_grid() {
        // Create a 2x2 grid of squares
        // 0,0 - 10,0 - 20,0
        //  |     |      |
        // 0,10- 10,10- 20,10
        //  |     |      |
        // 0,20- 10,20- 20,20

        let mut geoms = Vec::new();

        // Horizontals
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 0.0 }, Coord { x: 20.0, y: 0.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 10.0 }, Coord { x: 20.0, y: 10.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 20.0 }, Coord { x: 20.0, y: 20.0 }])));

        // Verticals
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 0.0 }, Coord { x: 0.0, y: 20.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 10.0, y: 0.0 }, Coord { x: 10.0, y: 20.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 20.0, y: 0.0 }, Coord { x: 20.0, y: 20.0 }])));

        // BBox covers 0,0 to 20,20
        let bbox = Rect::new(Coord { x: 0.0, y: 0.0 }, Coord { x: 20.0, y: 20.0 });

        // Tile size 10 (exactly matching lines) or 15 (offset)
        // Let's try 15 to ensure polygons span tiles
        // Add buffer of 5.0 to ensure full polygons are captured in each tile
        let mut tiler = TiledPolygonizer::new(bbox, 15.0).with_buffer(5.0);

        for g in geoms {
            tiler.add_geometry(g);
        }

        let polys = tiler.polygonize();

        // Should find 4 polygons
        assert_eq!(polys.len(), 4);

        // Check areas
        for p in polys {
            use geo::Area;
            assert!((p.unsigned_area() - 100.0).abs() < 1e-6);
        }
    }

    #[test]
    fn test_tiled_polygonization_exact_boundary() {
        // Tile size 10, lines on 10.
        // This tests the "ownership" logic at boundaries.

        let mut geoms = Vec::new();
         // Horizontals
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 0.0 }, Coord { x: 20.0, y: 0.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 10.0 }, Coord { x: 20.0, y: 10.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 20.0 }, Coord { x: 20.0, y: 20.0 }])));

        // Verticals
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 0.0, y: 0.0 }, Coord { x: 0.0, y: 20.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 10.0, y: 0.0 }, Coord { x: 10.0, y: 20.0 }])));
        geoms.push(Geometry::LineString(LineString::new(vec![Coord { x: 20.0, y: 0.0 }, Coord { x: 20.0, y: 20.0 }])));

        let bbox = Rect::new(Coord { x: 0.0, y: 0.0 }, Coord { x: 20.0, y: 20.0 });

        // Tile size 10.
        // Tiles: [0,10]x[0,10], [10,20]x[0,10], etc.
        let mut tiler = TiledPolygonizer::new(bbox, 10.0);

        for g in geoms {
            tiler.add_geometry(g);
        }

        let polys = tiler.polygonize();

        assert_eq!(polys.len(), 4);
    }
}

```

File: src/wasm.rs
```
use wasm_bindgen::prelude::*;
use crate::Polygonizer;
use geojson::{GeoJson, Geometry, Value};
use std::convert::TryInto;
use std::str::FromStr;

#[wasm_bindgen]
pub fn polygonize(geojson_str: &str) -> Result<String, JsValue> {
    // Set panic hook for better error messages
    #[cfg(feature = "console_error_panic_hook")]
    console_error_panic_hook::set_once();

    let geojson = GeoJson::from_str(geojson_str)
        .map_err(|e| JsValue::from_str(&format!("Invalid GeoJSON: {}", e)))?;

    let mut polygonizer = Polygonizer::new();

    // Process inputs
    match geojson {
        GeoJson::FeatureCollection(fc) => {
            for feature in fc.features {
                if let Some(geom) = feature.geometry {
                    let geo_geom: geo::Geometry<f64> = geom.try_into()
                        .map_err(|e| JsValue::from_str(&format!("Conversion error: {}", e)))?;
                    polygonizer.add_geometry(geo_geom);
                }
            }
        },
        GeoJson::Feature(f) => {
             if let Some(geom) = f.geometry {
                let geo_geom: geo::Geometry<f64> = geom.try_into()
                    .map_err(|e| JsValue::from_str(&format!("Conversion error: {}", e)))?;
                polygonizer.add_geometry(geo_geom);
            }
        },
        GeoJson::Geometry(g) => {
            let geo_geom: geo::Geometry<f64> = g.try_into()
                .map_err(|e| JsValue::from_str(&format!("Conversion error: {}", e)))?;
            polygonizer.add_geometry(geo_geom);
        }
    }

    let polygons = polygonizer.polygonize()
        .map_err(|e| JsValue::from_str(&format!("Polygonization error: {}", e)))?;

    // Convert back to GeoJSON
    let geometries: Vec<Geometry> = polygons.into_iter()
        .map(|p| Geometry::new(Value::from(&p)))
        .collect();

    // Wrap in FeatureCollection? Or GeometryCollection?
    // Let's return a FeatureCollection as it's standard for multiple geometries
    let mut features = Vec::new();
    for geom in geometries {
        features.push(geojson::Feature {
            bbox: None,
            geometry: Some(geom),
            id: None,
            properties: None,
            foreign_members: None,
        });
    }

    let fc = GeoJson::FeatureCollection(geojson::FeatureCollection {
        bbox: None,
        features,
        foreign_members: None,
    });

    Ok(fc.to_string())
}

```

File: src/graph/mod.rs
```
pub mod planar_graph;
pub use planar_graph::{PlanarGraph, NodeId, EdgeId, DirEdgeId};

#[cfg(test)]
mod tests;

```

File: src/graph/planar_graph.rs
```
use geo_types::{Coord, LineString};
use geo::Line;
use std::collections::HashMap;
#[cfg(feature = "parallel")]
use rayon::prelude::*;
use crate::utils::{z_order_index, compare_angular};

// Type aliases for indices to ensure we don't mix them up
pub type NodeId = usize;
pub type EdgeId = usize;
pub type DirEdgeId = usize;

#[derive(Clone, Debug)]
pub struct Edge {
    // The geometry of the edge.
    // In JTS this might be a full LineString, but for the graph we mainly care about connectivity.
    // We store Line to reduce heap allocations compared to LineString.
    pub line: Line<f64>,
    // Indices of the two directed edges associated with this undirected edge.
    pub dir_edges: [DirEdgeId; 2],
    pub is_marked: bool,
}

#[derive(Clone, Debug)]
pub struct DirectedEdge {
    pub src: NodeId,
    pub dst: NodeId,
    /// Reference to the parent geometry (undirected edge)
    pub edge_idx: EdgeId,
    /// Index of the symmetric (reverse) edge
    pub sym_idx: DirEdgeId,
    /// Traversal state: has this edge been processed into a ring?
    pub is_visited: bool,
    /// Is this edge explicitly marked (e.g. as part of a dangle)
    pub is_marked: bool,
    /// Orientation in the parent LineString (true: same direction, false: opposite)
    pub edge_direction: bool,
}

pub struct PlanarGraph {
    /// Node coordinates (X). Index is `NodeId`.
    pub nodes_x: Vec<f64>,
    /// Node coordinates (Y). Index is `NodeId`.
    pub nodes_y: Vec<f64>,
    /// Node adjacency lists. Index is `NodeId`.
    pub nodes_outgoing: Vec<Vec<DirEdgeId>>,
    /// Node connectivity degrees. Index is `NodeId`.
    pub nodes_degree: Vec<usize>,
    /// Node marked flags. Index is `NodeId`.
    pub nodes_marked: Vec<bool>,

    /// All undirected edges (geometry owners). Index is `EdgeId`.
    pub edges: Vec<Edge>,
    /// All directed half-edges. Index is `DirEdgeId`.
    pub directed_edges: Vec<DirectedEdge>,
    /// Lookup map to dedup nodes during construction.
    /// OPTIMIZATION: Used only for incremental additions. Bulk load bypasses this.
    pub node_map: HashMap<NodeKey, NodeId>,
}

// Wrapper for Coord to be Hashable (since f64 is not Hash)
#[derive(PartialEq, Eq, Hash, Clone, Copy)]
pub struct NodeKey(i64, i64);

impl From<Coord<f64>> for NodeKey {
    fn from(c: Coord<f64>) -> Self {
        // Simple quantization for map lookup.
        NodeKey(c.x.to_bits() as i64, c.y.to_bits() as i64)
    }
}

impl PlanarGraph {
    pub fn new() -> Self {
        Self {
            nodes_x: Vec::new(),
            nodes_y: Vec::new(),
            nodes_outgoing: Vec::new(),
            nodes_degree: Vec::new(),
            nodes_marked: Vec::new(),
            edges: Vec::new(),
            directed_edges: Vec::new(),
            node_map: HashMap::new(),
        }
    }

    pub fn add_node(&mut self, coord: Coord<f64>) -> NodeId {
        let key = NodeKey::from(coord);
        if let Some(&id) = self.node_map.get(&key) {
            return id;
        }

        let id = self.nodes_x.len();
        self.nodes_x.push(coord.x);
        self.nodes_y.push(coord.y);
        self.nodes_outgoing.push(Vec::new());
        self.nodes_degree.push(0);
        self.nodes_marked.push(false);
        self.node_map.insert(key, id);
        id
    }

    /// Bulk loads edges into the graph.
    /// This is significantly faster than `add_line_string` for large datasets as it avoids HashMap lookups.
    pub fn bulk_load(&mut self, lines: Vec<Line<f64>>) {
        if lines.is_empty() {
            return;
        }

        // 1. Collect all coordinates and precompute Z-order
        struct NodeEntry {
            z: u64,
            c: Coord<f64>,
        }

        // Parallelize Z-order calculation
        #[cfg(feature = "parallel")]
        let mut entries: Vec<NodeEntry> = lines.par_iter()
            .flat_map_iter(|line| {
                 let z1 = z_order_index(line.start);
                 let z2 = z_order_index(line.end);
                 [NodeEntry { z: z1, c: line.start }, NodeEntry { z: z2, c: line.end }]
            })
            .collect();

        #[cfg(not(feature = "parallel"))]
        let mut entries: Vec<NodeEntry> = {
            let mut v = Vec::with_capacity(lines.len() * 2);
            for line in &lines {
                v.push(NodeEntry { z: z_order_index(line.start), c: line.start });
                v.push(NodeEntry { z: z_order_index(line.end), c: line.end });
            }
            v
        };

        // 2. Sort using precomputed Z-order
        #[cfg(feature = "parallel")]
        entries.par_sort_unstable_by(|a, b| {
            a.z.cmp(&b.z)
                .then_with(|| {
                    // Tie-break with exact coords for determinism/dedup
                    a.c.x.partial_cmp(&b.c.x).unwrap_or(std::cmp::Ordering::Equal)
                        .then(a.c.y.partial_cmp(&b.c.y).unwrap_or(std::cmp::Ordering::Equal))
                })
        });

        #[cfg(not(feature = "parallel"))]
        entries.sort_unstable_by(|a, b| {
             a.z.cmp(&b.z)
                .then_with(|| {
                    // Tie-break with exact coords
                    a.c.x.partial_cmp(&b.c.x).unwrap_or(std::cmp::Ordering::Equal)
                        .then(a.c.y.partial_cmp(&b.c.y).unwrap_or(std::cmp::Ordering::Equal))
                })
        });

        // Dedup using exact equality.
        entries.dedup_by(|a, b| {
            // Strict equality to match binary_search and add_node behavior
            a.c == b.c
        });

        // 3. Build Nodes
        let start_node_idx = self.nodes_x.len();
        self.nodes_x.reserve(entries.len());
        self.nodes_y.reserve(entries.len());
        self.nodes_outgoing.reserve(entries.len());
        self.nodes_degree.reserve(entries.len());
        self.nodes_marked.reserve(entries.len());

        for entry in &entries {
            self.nodes_x.push(entry.c.x);
            self.nodes_y.push(entry.c.y);
            self.nodes_outgoing.push(Vec::new());
            self.nodes_degree.push(0);
            self.nodes_marked.push(false);
        }

        // Helper to find node index using precomputed Z array (entries)
        let get_node_id = |pt: Coord<f64>| -> Option<NodeId> {
             // Binary search must respect the sort order (Z-order)
             let z_pt = z_order_index(pt);

             // Binary search on the sorted entries
             let idx_res = entries.binary_search_by(|probe| {
                 probe.z.cmp(&z_pt)
                    .then_with(|| {
                        probe.c.x.partial_cmp(&pt.x).unwrap_or(std::cmp::Ordering::Equal)
                            .then(probe.c.y.partial_cmp(&pt.y).unwrap_or(std::cmp::Ordering::Equal))
                    })
             });

             match idx_res {
                 Ok(i) => Some(start_node_idx + i),
                 Err(_) => None
             }
        };

        // 4. Precompute Adjacency Lists sizes
        // We do a first pass to map endpoints to node IDs and count degrees.
        // This allows us to reserve exact capacity for outgoing_edges.
        // It also avoids repeated binary searches in the second pass.

        // Store valid edges as (u, v, line)
        let mut valid_edges = Vec::with_capacity(lines.len());
        let mut degrees = vec![0usize; self.nodes_x.len()]; // This might be large?

        for line in lines {
             let p0 = line.start;
             let p1 = line.end;

             if (p0.x - p1.x).abs() < 1e-12 && (p0.y - p1.y).abs() < 1e-12 {
                continue;
            }

            let u_opt = get_node_id(p0);
            let v_opt = get_node_id(p1);

            if let (Some(u), Some(v)) = (u_opt, v_opt) {
                valid_edges.push((u, v, line));
                degrees[u] += 1;
                degrees[v] += 1;
            }
        }

        // Reserve exact capacity
        #[cfg(feature = "parallel")]
        self.nodes_outgoing.par_iter_mut().zip(degrees.par_iter()).for_each(|(adj, &deg)| {
            adj.reserve(deg);
        });

        #[cfg(not(feature = "parallel"))]
        self.nodes_outgoing.iter_mut().zip(degrees.iter()).for_each(|(adj, &deg)| {
            adj.reserve(deg);
        });

        // 5. Build Edges
        self.edges.reserve(valid_edges.len());
        self.directed_edges.reserve(valid_edges.len() * 2);

        #[cfg(feature = "parallel")]
        let new_edges_data: Vec<_> = valid_edges.into_par_iter().enumerate().map(|(i, (u, v, line))| {
            let edge_idx = self.edges.len() + i;
            let de_u_v_idx = self.directed_edges.len() + 2 * i;
            let de_v_u_idx = self.directed_edges.len() + 2 * i + 1;

            let de_u_v = DirectedEdge {
                src: u,
                dst: v,
                edge_idx,
                sym_idx: de_v_u_idx,
                is_visited: false,
                is_marked: false,
                edge_direction: true,
            };

            let de_v_u = DirectedEdge {
                src: v,
                dst: u,
                edge_idx,
                sym_idx: de_u_v_idx,
                is_visited: false,
                is_marked: false,
                edge_direction: false,
            };

            let edge = Edge {
                line,
                dir_edges: [de_u_v_idx, de_v_u_idx],
                is_marked: false,
            };

            (u, v, de_u_v_idx, de_v_u_idx, de_u_v, de_v_u, edge)
        }).collect();

        #[cfg(not(feature = "parallel"))]
        let new_edges_data: Vec<_> = valid_edges.into_iter().enumerate().map(|(i, (u, v, line))| {
             let edge_idx = self.edges.len() + i;
             let de_u_v_idx = self.directed_edges.len() + 2 * i;
             let de_v_u_idx = self.directed_edges.len() + 2 * i + 1;

             let de_u_v = DirectedEdge {
                 src: u,
                 dst: v,
                 edge_idx,
                 sym_idx: de_v_u_idx,
                 is_visited: false,
                 is_marked: false,
                 edge_direction: true,
             };

             let de_v_u = DirectedEdge {
                 src: v,
                 dst: u,
                 edge_idx,
                 sym_idx: de_u_v_idx,
                 is_visited: false,
                 is_marked: false,
                 edge_direction: false,
             };

             let edge = Edge {
                 line,
                 dir_edges: [de_u_v_idx, de_v_u_idx],
                 is_marked: false,
             };
            (u, v, de_u_v_idx, de_v_u_idx, de_u_v, de_v_u, edge)
        }).collect();

        for (u, v, de_u_v_idx, de_v_u_idx, de_u_v, de_v_u, edge) in new_edges_data {
            self.directed_edges.push(de_u_v);
            self.directed_edges.push(de_v_u);
            self.edges.push(edge);

            self.nodes_outgoing[u].push(de_u_v_idx);
            self.nodes_degree[u] += 1;
            self.nodes_outgoing[v].push(de_v_u_idx);
            self.nodes_degree[v] += 1;
        }
    }

    /// Adds a line string to the graph.
    pub fn add_line_string(&mut self, line: LineString<f64>) {
        if line.0.is_empty() {
            return;
        }

        let coords = &line.0;
        for i in 0..coords.len().saturating_sub(1) {
            let p0 = coords[i];
            let p1 = coords[i+1];

            if (p0.x - p1.x).abs() < 1e-12 && (p0.y - p1.y).abs() < 1e-12 {
                continue;
            }

            let u = self.add_node(p0);
            let v = self.add_node(p1);

            let edge_idx = self.edges.len();

            let de_u_v_idx = self.directed_edges.len();
            let de_v_u_idx = self.directed_edges.len() + 1;

            let de_u_v = DirectedEdge {
                src: u,
                dst: v,
                edge_idx,
                sym_idx: de_v_u_idx,
                is_visited: false,
                is_marked: false,
                edge_direction: true,
            };

            let de_v_u = DirectedEdge {
                src: v,
                dst: u,
                edge_idx,
                sym_idx: de_u_v_idx,
                is_visited: false,
                is_marked: false,
                edge_direction: false,
            };

            self.directed_edges.push(de_u_v);
            self.directed_edges.push(de_v_u);

            self.edges.push(Edge {
                line: Line::new(p0, p1),
                dir_edges: [de_u_v_idx, de_v_u_idx],
                is_marked: false,
            });

            self.nodes_outgoing[u].push(de_u_v_idx);
            self.nodes_degree[u] += 1;

            self.nodes_outgoing[v].push(de_v_u_idx);
            self.nodes_degree[v] += 1;
        }
    }

    /// Sorts all outgoing edges of all nodes by angle.
    pub fn sort_edges(&mut self) {
        let nodes_x = &self.nodes_x;
        let nodes_y = &self.nodes_y;
        let directed_edges = &self.directed_edges;

        // Use a robust angular comparator.
        // This requires accessing coordinates of src and dst nodes.
        #[cfg(feature = "parallel")]
        self.nodes_outgoing.par_iter_mut().enumerate().for_each(|(src_idx, adj)| {
             let center = Coord { x: nodes_x[src_idx], y: nodes_y[src_idx] };
             adj.sort_by(|&a_idx, &b_idx| {
                 let a_de = &directed_edges[a_idx];
                 let b_de = &directed_edges[b_idx];

                 // Get destination coordinates
                 let dst_a_idx = a_de.dst;
                 let dst_b_idx = b_de.dst;

                 let target_a = Coord { x: nodes_x[dst_a_idx], y: nodes_y[dst_a_idx] };
                 let target_b = Coord { x: nodes_x[dst_b_idx], y: nodes_y[dst_b_idx] };

                 compare_angular(center, target_a, target_b)
             });
        });

        #[cfg(not(feature = "parallel"))]
        self.nodes_outgoing.iter_mut().enumerate().for_each(|(src_idx, adj)| {
             let center = Coord { x: nodes_x[src_idx], y: nodes_y[src_idx] };
             adj.sort_by(|&a_idx, &b_idx| {
                 let a_de = &directed_edges[a_idx];
                 let b_de = &directed_edges[b_idx];

                 let dst_a_idx = a_de.dst;
                 let dst_b_idx = b_de.dst;

                 let target_a = Coord { x: nodes_x[dst_a_idx], y: nodes_y[dst_a_idx] };
                 let target_b = Coord { x: nodes_x[dst_b_idx], y: nodes_y[dst_b_idx] };

                 compare_angular(center, target_a, target_b)
             });
        });
    }

    /// Prunes dangles (nodes with degree 1) from the graph iteratively.
    pub fn prune_dangles(&mut self) -> usize {
        let mut dangles_removed = 0;
        let mut to_process: Vec<NodeId> = self.nodes_degree.iter().enumerate()
            .filter(|(i, &d)| d == 1 && !self.nodes_marked[*i])
            .map(|(i, _)| i)
            .collect();

        while let Some(node_idx) = to_process.pop() {
            if self.nodes_degree[node_idx] != 1 {
                continue;
            }

            self.nodes_marked[node_idx] = true;
            self.nodes_degree[node_idx] = 0;
            dangles_removed += 1;

            let mut edge_found = false;
            let mut neighbor_idx = 0;

            let mut found_de_idx = None;
            for &de_idx in &self.nodes_outgoing[node_idx] {
                if !self.directed_edges[de_idx].is_marked {
                    found_de_idx = Some(de_idx);
                    break;
                }
            }

            if let Some(de_idx) = found_de_idx {
                self.directed_edges[de_idx].is_marked = true;
                let sym_idx = self.directed_edges[de_idx].sym_idx;
                self.directed_edges[sym_idx].is_marked = true;

                neighbor_idx = self.directed_edges[de_idx].dst;
                edge_found = true;
            }

            if edge_found {
                if self.nodes_degree[neighbor_idx] > 0 {
                    self.nodes_degree[neighbor_idx] -= 1;
                    if self.nodes_degree[neighbor_idx] == 1 && !self.nodes_marked[neighbor_idx] {
                        to_process.push(neighbor_idx);
                    }
                }
            }
        }
        dangles_removed
    }

    /// Extracts rings from the graph using the Next-CCW rule.
    pub fn get_edge_rings(&mut self) -> Vec<LineString<f64>> {
        let mut rings = Vec::new();

        // Build "next unmarked" pointers
        // next_pointers[de_idx] = the index of the next valid (unmarked) edge
        // in the CCW list of the node that de_idx originates from.
        // During traversal, we look at next_pointers[sym_idx], which gives us the
        // edge after the incoming edge (sym) in CCW order at the node.
        let mut next_pointers = vec![usize::MAX; self.directed_edges.len()];

        for (i, degree) in self.nodes_degree.iter().enumerate() {
            if *degree == 0 { continue; }

            // Filter out marked edges from the adjacency list
            let valid_edges: Vec<usize> = self.nodes_outgoing[i].iter()
                .cloned()
                .filter(|&idx| !self.directed_edges[idx].is_marked)
                .collect();

            if valid_edges.is_empty() { continue; }

            // Link them circular
            for k in 0..valid_edges.len() {
                let curr = valid_edges[k];
                let next = valid_edges[(k + 1) % valid_edges.len()];
                next_pointers[curr] = next;
            }
        }

        for de in &mut self.directed_edges {
            de.is_visited = false;
        }

        // Reuse vector to avoid allocations
        let mut ring_edges = Vec::new();

        for start_de_idx in 0..self.directed_edges.len() {
            if self.directed_edges[start_de_idx].is_visited || self.directed_edges[start_de_idx].is_marked {
                continue;
            }

            ring_edges.clear();
            let mut curr_de_idx = start_de_idx;
            let mut is_valid_ring = true;

            loop {
                let curr_de = &mut self.directed_edges[curr_de_idx];
                curr_de.is_visited = true;
                ring_edges.push(curr_de_idx);

                let sym_idx = curr_de.sym_idx;
                let next_de_idx = next_pointers[sym_idx];

                if next_de_idx == usize::MAX {
                    is_valid_ring = false;
                    break;
                }

                curr_de_idx = next_de_idx;

                if curr_de_idx == start_de_idx {
                    break;
                }

                if self.directed_edges[curr_de_idx].is_visited {
                    is_valid_ring = false;
                    break;
                }
            }

            if is_valid_ring && !ring_edges.is_empty() {
                let mut coords = Vec::with_capacity(ring_edges.len() + 1);
                let start_node_idx = self.directed_edges[ring_edges[0]].src;
                coords.push(Coord { x: self.nodes_x[start_node_idx], y: self.nodes_y[start_node_idx] });

                for &de_idx in &ring_edges {
                    let de = &self.directed_edges[de_idx];
                    let dst_idx = de.dst;
                    coords.push(Coord { x: self.nodes_x[dst_idx], y: self.nodes_y[dst_idx] });
                }

                rings.push(LineString::new(coords));
            }
        }

        rings
    }
}

```

File: src/graph/tests.rs
```
#[cfg(test)]
mod tests {
    use crate::graph::planar_graph::PlanarGraph;
    use geo_types::{Coord, LineString};

    #[test]
    fn test_graph_construction() {
        let mut graph = PlanarGraph::new();
        let l1 = LineString::from(vec![(0.0, 0.0), (10.0, 0.0)]);
        let l2 = LineString::from(vec![(0.0, 0.0), (0.0, 10.0)]);

        graph.add_line_string(l1);
        graph.add_line_string(l2);

        assert_eq!(graph.nodes_x.len(), 3); // (0,0), (10,0), (0,10)
        assert_eq!(graph.edges.len(), 2);
        assert_eq!(graph.directed_edges.len(), 4);

        // Node at (0,0) should have 2 outgoing edges
        let center_node_idx = graph.node_map.get(&Coord::from((0.0, 0.0)).into()).unwrap();
        assert_eq!(graph.nodes_outgoing[*center_node_idx].len(), 2);
    }

    #[test]
    fn test_edge_sorting() {
        let mut graph = PlanarGraph::new();
        // Add 4 edges radiating from (0,0)
        // 1. Right (0 degrees) -> dx=10, dy=0
        graph.add_line_string(LineString::from(vec![(0.0, 0.0), (10.0, 0.0)]));
        // 2. Up (90 degrees) -> dx=0, dy=10
        graph.add_line_string(LineString::from(vec![(0.0, 0.0), (0.0, 10.0)]));
        // 3. Left (180 degrees) -> dx=-10, dy=0
        graph.add_line_string(LineString::from(vec![(0.0, 0.0), (-10.0, 0.0)]));
        // 4. Down (-90 degrees) -> dx=0, dy=-10
        graph.add_line_string(LineString::from(vec![(0.0, 0.0), (0.0, -10.0)]));

        graph.sort_edges();

        let center_node_idx = graph.node_map.get(&Coord::from((0.0, 0.0)).into()).unwrap();

        let edges = &graph.nodes_outgoing[*center_node_idx];
        assert_eq!(edges.len(), 4);

        // We expect the sort order to be CCW starting from +X axis.
        // Right, Up, Left, Down
        // Check destination coordinates to verify.
        let get_dst = |idx: usize| -> (f64, f64) {
            let dst_node_idx = graph.directed_edges[idx].dst;
            (graph.nodes_x[dst_node_idx], graph.nodes_y[dst_node_idx])
        };

        let dst0 = get_dst(edges[0]);
        let dst1 = get_dst(edges[1]);
        let dst2 = get_dst(edges[2]);
        let dst3 = get_dst(edges[3]);

        // Right
        assert!(dst0.0 > 0.0 && dst0.1.abs() < 1e-6, "Expected Right (10, 0), got {:?}", dst0);
        // Up
        assert!(dst1.0.abs() < 1e-6 && dst1.1 > 0.0, "Expected Up (0, 10), got {:?}", dst1);
        // Left
        assert!(dst2.0 < 0.0 && dst2.1.abs() < 1e-6, "Expected Left (-10, 0), got {:?}", dst2);
        // Down
        assert!(dst3.0.abs() < 1e-6 && dst3.1 < 0.0, "Expected Down (0, -10), got {:?}", dst3);
    }

    #[test]
    fn test_dangle_pruning() {
        let mut graph = PlanarGraph::new();
        // Triangle with a dangle
        graph.add_line_string(LineString::from(vec![(0.0, 0.0), (10.0, 0.0)]));
        graph.add_line_string(LineString::from(vec![(10.0, 0.0), (0.0, 10.0)]));
        graph.add_line_string(LineString::from(vec![(0.0, 10.0), (0.0, 0.0)]));

        // Dangle at B
        graph.add_line_string(LineString::from(vec![(10.0, 0.0), (20.0, 0.0)]));

        graph.sort_edges();

        let dangles = graph.prune_dangles();
        assert_eq!(dangles, 1);

        let b_idx = graph.node_map.get(&Coord::from((10.0, 0.0)).into()).unwrap();
        assert_eq!(graph.nodes_degree[*b_idx], 2);
    }

    #[test]
    fn test_simple_cycle() {
        let mut graph = PlanarGraph::new();
        // Triangle
        graph.add_line_string(LineString::from(vec![(0.0, 0.0), (10.0, 0.0)]));
        graph.add_line_string(LineString::from(vec![(10.0, 0.0), (0.0, 10.0)]));
        graph.add_line_string(LineString::from(vec![(0.0, 10.0), (0.0, 0.0)]));

        graph.sort_edges();
        let rings = graph.get_edge_rings();

        assert_eq!(rings.len(), 2);
    }
}

```

File: src/noding/mod.rs
```
pub mod snap;

```

File: src/noding/snap.rs
```
use geo::{Line, Coord};
use rstar::{RTree, RTreeObject, AABB};
use std::cmp::Ordering;
use geo::algorithm::line_intersection::LineIntersection;

#[derive(Clone, Copy, Debug)]
struct IndexedLine {
    line: Line<f64>,
    index: usize,
}

impl RTreeObject for IndexedLine {
    type Envelope = AABB<[f64; 2]>;
    fn envelope(&self) -> Self::Envelope {
        let p1 = self.line.start;
        let p2 = self.line.end;
        AABB::from_corners(
            [p1.x.min(p2.x), p1.y.min(p2.y)],
            [p1.x.max(p2.x), p1.y.max(p2.y)]
        )
    }
}

pub struct SnapNoder {
    pub grid_size: f64,
    pub max_iter: usize,
}

impl SnapNoder {
    pub fn new(grid_size: f64) -> Self {
        Self { grid_size, max_iter: 10 }
    }

    pub fn node(&self, mut lines: Vec<Line<f64>>) -> Vec<Line<f64>> {
        // 1. Initial Snap of endpoints
        for line in &mut lines {
            line.start = self.snap(line.start);
            line.end = self.snap(line.end);
        }

        // Remove degenerates
        lines.retain(|l| l.start != l.end);

        // 2. Iterative Noding
        for _ in 0..self.max_iter {
            // Check for intersections
            let split_map = self.find_splits(&lines);

            if split_map.is_empty() {
                break;
            }

            // Apply splits
            let mut new_lines = Vec::with_capacity(lines.len() * 2);
            for (i, line) in lines.iter().enumerate() {
                if let Some(splits) = split_map.get(&i) {
                    let mut points = splits.clone();
                    // Add endpoints
                    points.push(line.start);
                    points.push(line.end);

                    // Sort by distance from start
                    let start = line.start;
                    points.sort_by(|a, b| {
                        let da = (a.x - start.x).powi(2) + (a.y - start.y).powi(2);
                        let db = (b.x - start.x).powi(2) + (b.y - start.y).powi(2);
                        da.partial_cmp(&db).unwrap_or(Ordering::Equal)
                    });

                    points.dedup();

                    // Create segments
                    for w in points.windows(2) {
                        let p0 = w[0];
                        let p1 = w[1];
                        if p0 != p1 {
                            new_lines.push(Line::new(p0, p1));
                        }
                    }
                } else {
                    new_lines.push(*line);
                }
            }

            // Deduplicate segments?
            // Yes, duplicate segments are common in noding.
            // Also normalize direction.
             for segment in &mut new_lines {
                if segment.start.x > segment.end.x ||
                   ((segment.start.x - segment.end.x).abs() < 1e-12 && segment.start.y > segment.end.y) {
                     let temp = segment.start;
                     segment.start = segment.end;
                     segment.end = temp;
                }
            }
            new_lines.sort_by(|a, b| {
                 let sa = (a.start.x, a.start.y, a.end.x, a.end.y);
                 let sb = (b.start.x, b.start.y, b.end.x, b.end.y);
                 sa.partial_cmp(&sb).unwrap_or(Ordering::Equal)
            });
            new_lines.dedup();

            lines = new_lines;
        }

        lines
    }

    fn snap(&self, c: Coord<f64>) -> Coord<f64> {
        if self.grid_size == 0.0 { return c; }
        Coord {
            x: (c.x / self.grid_size).round() * self.grid_size,
            y: (c.y / self.grid_size).round() * self.grid_size,
        }
    }

    fn find_splits(&self, lines: &[Line<f64>]) -> std::collections::HashMap<usize, Vec<Coord<f64>>> {
        let mut splits = std::collections::HashMap::new();

        let indexed: Vec<IndexedLine> = lines.iter().enumerate()
            .map(|(i, l)| IndexedLine { line: *l, index: i })
            .collect();

        let tree = RTree::bulk_load(indexed);

        // Find intersections
        let candidates = tree.intersection_candidates_with_other_tree(&tree);

        for (idx1, idx2) in candidates {
            let i = idx1.index;
            let j = idx2.index;
            if i >= j { continue; } // Handle unique pairs

            let l1 = idx1.line;
            let l2 = idx2.line;

            // Fast bounding box check (handled by RTree, but good to be sure)

            // Intersection
            if let Some(res) = geo::algorithm::line_intersection::line_intersection(l1, l2) {
                 match res {
                    LineIntersection::SinglePoint { intersection: pt, .. } => {
                        let snapped = self.snap(pt);

                        // Check if split needed for L1
                        if snapped != l1.start && snapped != l1.end {
                            splits.entry(i).or_insert_with(Vec::new).push(snapped);
                        }
                        // Check if split needed for L2
                        if snapped != l2.start && snapped != l2.end {
                            splits.entry(j).or_insert_with(Vec::new).push(snapped);
                        }
                    },
                    LineIntersection::Collinear { intersection: overlap } => {
                        // For collinear, we split at the overlap endpoints
                        let p1 = self.snap(overlap.start);
                        let p2 = self.snap(overlap.end);

                        for p in [p1, p2] {
                             if p != l1.start && p != l1.end {
                                 splits.entry(i).or_insert_with(Vec::new).push(p);
                             }
                             if p != l2.start && p != l2.end {
                                 splits.entry(j).or_insert_with(Vec::new).push(p);
                             }
                        }
                    }
                 }
            }
        }

        splits
    }
}

```

File: src/utils/mod.rs
```
use geo_types::Coord;
use robust::{orient2d, Coord as RobustCoord};
use std::cmp::Ordering;

pub mod parallel;
pub mod simd;

/// Computes a Z-order curve (Morton code) index for a 2D coordinate.
/// Maps floating point coordinates to a 64-bit integer index.
/// This preserves locality: points close in 2D space are likely close in Z-order.
pub fn z_order_index(c: Coord<f64>) -> u64 {
    let x = sortable_float(c.x);
    let y = sortable_float(c.y);
    part1by1(x as u64) | (part1by1(y as u64) << 1)
}

#[inline]
fn sortable_float(f: f64) -> u64 {
    let bits = f.to_bits();
    if bits & 0x8000000000000000 != 0 {
        !bits
    } else {
        bits ^ 0x8000000000000000
    }
}

// Interleave lower 32 bits to 64 bits
#[inline]
fn part1by1(mut n: u64) -> u64 {
    n &= 0x00000000FFFFFFFF;
    n = (n | (n << 16)) & 0x0000FFFF0000FFFF;
    n = (n | (n << 8))  & 0x00FF00FF00FF00FF;
    n = (n | (n << 4))  & 0x0F0F0F0F0F0F0F0F;
    n = (n | (n << 2))  & 0x3333333333333333;
    n = (n | (n << 1))  & 0x5555555555555555;
    n
}

/// Robust comparator for angular sorting of edges around a center point.
/// Replaces the need for `pseudo_angle`.
///
/// Sorts vectors `u` and `v` starting at `center` in counter-clockwise order
/// starting from the positive X-axis.
///
/// Returns `Ordering` such that a < b if a comes before b in CCW order.
pub fn compare_angular(center: Coord<f64>, target_a: Coord<f64>, target_b: Coord<f64>) -> Ordering {
    if target_a == target_b {
        return Ordering::Equal;
    }

    // Determine quadrants
    // 0: [0, 90)   (x>0, y>=0)
    // 1: [90, 180) (x<=0, y>0)
    // 2: [180, 270) (x<0, y<=0)
    // 3: [270, 360) (x>=0, y<0)
    let quad_a = quadrant(center, target_a);
    let quad_b = quadrant(center, target_b);

    if quad_a != quad_b {
        return quad_a.cmp(&quad_b);
    }

    // Same quadrant: use robust orientation check
    // If orient2d(center, a, b) > 0, then b is Left of a (CCW).
    // So a < b.
    let c = RobustCoord { x: center.x, y: center.y };
    let a = RobustCoord { x: target_a.x, y: target_a.y };
    let b = RobustCoord { x: target_b.x, y: target_b.y };

    let orient = orient2d(c, a, b);

    if orient > 0.0 {
        Ordering::Less // a is before b (b is CCW of a)
    } else if orient < 0.0 {
        Ordering::Greater // b is before a (a is CCW of b)
    } else {
        // Collinear rays
        // Sort by distance (shorter first? longer first?)
        // For simple polygonization, dedup usually handles this.
        // Let's pick: Farthest first?
        let dist_a = (target_a.x - center.x).powi(2) + (target_a.y - center.y).powi(2);
        let dist_b = (target_b.x - center.x).powi(2) + (target_b.y - center.y).powi(2);
        dist_a.partial_cmp(&dist_b).unwrap_or(Ordering::Equal)
    }
}

fn quadrant(c: Coord<f64>, t: Coord<f64>) -> u8 {
    let dx = t.x - c.x;
    let dy = t.y - c.y;

    if dx > 0.0 && dy >= 0.0 { 0 }
    else if dx <= 0.0 && dy > 0.0 { 1 }
    else if dx < 0.0 && dy <= 0.0 { 2 }
    else { 3 }
}

```

File: src/utils/parallel.rs
```

#[cfg(feature = "parallel")]
use rayon::prelude::*;

/// A trait to switch between parallel and sequential iterators
pub trait MaybeParIter<T> {
    type Iter: Iterator<Item = T>;
    fn maybe_par_iter(self) -> Self::Iter;
}

// Helper to switch based on size or architecture
// Note: This helper runs for_each
#[inline]
pub fn iterate<T, F>(collection: &[T], f: F)
where T: Sync, F: Fn(&T) + Sync + Send {
    #[cfg(all(feature = "parallel", not(target_arch = "wasm32")))]
    {
        // Heuristic: Don't spin up Rayon for < 1000 items
        if collection.len() > 1000 {
            collection.par_iter().for_each(f);
        } else {
            collection.iter().for_each(f);
        }
    }
    #[cfg(any(not(feature = "parallel"), target_arch = "wasm32"))]
    {
        collection.iter().for_each(f);
    }
}

// Helper for mutable iteration
#[inline]
pub fn iterate_mut<T, F>(collection: &mut [T], f: F)
where T: Send, F: Fn(&mut T) + Sync + Send {
     #[cfg(all(feature = "parallel", not(target_arch = "wasm32")))]
    {
        if collection.len() > 1000 {
            collection.par_iter_mut().for_each(f);
        } else {
            collection.iter_mut().for_each(f);
        }
    }
    #[cfg(any(not(feature = "parallel"), target_arch = "wasm32"))]
    {
        collection.iter_mut().for_each(f);
    }
}

```

File: src/utils/simd.rs
```
use wide::f64x4;
use wide::CmpGt;
use geo::Coord;

pub struct SimdRing {
    pub x: Vec<f64>,
    pub y: Vec<f64>,
    len: usize,
}

impl SimdRing {
    pub fn new(coords: &[Coord<f64>]) -> Self {
        let len = coords.len();

        let mut x = Vec::with_capacity(len + 3);
        let mut y = Vec::with_capacity(len + 3);

        for c in coords {
            x.push(c.x);
            y.push(c.y);
        }

        while x.len() % 4 != 0 {
            x.push(x.last().cloned().unwrap_or(0.0));
            y.push(y.last().cloned().unwrap_or(0.0));
        }

        Self { x, y, len }
    }

    pub fn contains(&self, point: Coord<f64>) -> bool {
        let px = f64x4::splat(point.x);
        let py = f64x4::splat(point.y);

        let n = self.len - 1; // Number of segments

        let mut i = 0;
        let mut crossings = 0;

        while i < n {
            let remaining = n - i;
            if remaining >= 4 {
                let xi = f64x4::from(&self.x[i..i+4]);
                let yi = f64x4::from(&self.y[i..i+4]);

                let xj = f64x4::from(&self.x[i+1..i+5]);
                let yj = f64x4::from(&self.y[i+1..i+5]);

                let yi_gt_py = yi.cmp_gt(py);
                let yj_gt_py = yj.cmp_gt(py);
                let in_range = yi_gt_py ^ yj_gt_py;

                let num = (xj - xi) * (py - yi);
                let den = yj - yi;

                let intersect_x = (num / den) + xi;
                let x_cond = intersect_x.cmp_gt(px);

                let is_crossing = in_range & x_cond;

                crossings += is_crossing.move_mask().count_ones();

                i += 4;
            } else {
                let p1x = self.x[i];
                let p1y = self.y[i];
                let p2x = self.x[i+1];
                let p2y = self.y[i+1];

                if ((p1y > point.y) != (p2y > point.y)) &&
                   (point.x < (p2x - p1x) * (point.y - p1y) / (p2y - p1y) + p1x) {
                    crossings += 1;
                }
                i += 1;
            }
        }

        crossings % 2 != 0
    }
}

```

File: tests/integration_tests.rs
```
use geo_polygonize::Polygonizer;
use geo_types::{LineString, Geometry, Polygon, Coord};
use geo::Area;
use std::f64::consts::PI;

#[test]
fn test_nested_holes() {
    let mut poly = Polygonizer::new();

    // Outer Box (0,0) - (100,100)
    poly.add_geometry(LineString::from(vec![
        (0.0, 0.0), (100.0, 0.0), (100.0, 100.0), (0.0, 100.0), (0.0, 0.0)
    ]).into());

    // Inner Hole (20,20) - (80,80)
    poly.add_geometry(LineString::from(vec![
        (20.0, 20.0), (20.0, 80.0), (80.0, 80.0), (80.0, 20.0), (20.0, 20.0)
    ]).into());

    // Island inside Hole (40,40) - (60,60)
    poly.add_geometry(LineString::from(vec![
        (40.0, 40.0), (60.0, 40.0), (60.0, 60.0), (40.0, 60.0), (40.0, 40.0)
    ]).into());

    let polygons = poly.polygonize().unwrap();

    // The polygonizer produces a full mesh:
    // 1. The Donut (Outer - Hole). Area = 10000 - 3600 = 6400.
    // 2. The Filled Hole (Hole - Island). Area = 3600 - 400 = 3200.
    // 3. The Island. Area = 400.

    assert_eq!(polygons.len(), 3);

    let donut = polygons.iter().find(|p| (p.unsigned_area() - 6400.0).abs() < 1e-6);
    assert!(donut.is_some(), "Donut polygon with area 6400 not found");

    let filled_hole = polygons.iter().find(|p| (p.unsigned_area() - 3200.0).abs() < 1e-6);
    assert!(filled_hole.is_some(), "Filled hole polygon with area 3200 not found");

    let island = polygons.iter().find(|p| (p.unsigned_area() - 400.0).abs() < 1e-6);
    assert!(island.is_some(), "Island polygon with area 400 not found");
}

#[test]
fn test_touching_polygons() {
    let mut poly = Polygonizer::new();
    poly.node_input = true; // Required to deduplicate the shared edge

    // Square 1: (0,0)-(50,0)-(50,50)-(0,50)
    poly.add_geometry(LineString::from(vec![
        (0.0, 0.0), (50.0, 0.0), (50.0, 50.0), (0.0, 50.0), (0.0, 0.0)
    ]).into());

    // Square 2: (50,0)-(100,0)-(100,50)-(50,50)-(50,0)
    // Shared edge: (50,0)-(50,50)
    poly.add_geometry(LineString::from(vec![
        (50.0, 0.0), (100.0, 0.0), (100.0, 50.0), (50.0, 50.0), (50.0, 0.0)
    ]).into());

    let polygons = poly.polygonize().unwrap();

    // Should find 3 polygons (Mesh behavior):
    // 1. Square 1 (Area 2500)
    // 2. Square 2 (Area 2500)
    // 3. Union / Outer Shell (Area 5000) or similar.

    assert!(polygons.len() >= 2);

    let squares_count = polygons.iter().filter(|p| (p.unsigned_area() - 2500.0).abs() < 1e-6).count();
    assert_eq!(squares_count, 2, "Expected 2 squares of area 2500");
}

#[test]
fn test_dangles() {
    let mut poly = Polygonizer::new();
    // A square with a tail
    poly.add_geometry(LineString::from(vec![
        (0.0, 0.0), (10.0, 0.0), (10.0, 10.0), (0.0, 10.0), (0.0, 0.0)
    ]).into());

    // Tail
    poly.add_geometry(LineString::from(vec![
        (10.0, 10.0), (20.0, 20.0)
    ]).into());

    let polygons = poly.polygonize().unwrap();
    assert_eq!(polygons.len(), 1);
    assert!((polygons[0].unsigned_area() - 100.0).abs() < 1e-6);
}

#[test]
fn test_bowtie() {
    let mut poly = Polygonizer::new();
    poly.node_input = true;

    // Bowtie: (0,0)->(10,10)->(0,10)->(10,0)->(0,0)
    // Intersects at (5,5)
    poly.add_geometry(LineString::from(vec![
        (0.0, 0.0), (10.0, 10.0), (0.0, 10.0), (10.0, 0.0), (0.0, 0.0)
    ]).into());

    let polygons = poly.polygonize().unwrap();

    // Produces:
    // 1. Triangle 1 (Shell). Area 25.
    // 2. Triangle 2 (Shell). Area 25.
    // 3. The "Universe" or Outer Frame.

    assert!(polygons.len() >= 2);

    let triangles = polygons.iter().filter(|p| (p.unsigned_area() - 25.0).abs() < 1e-6).count();
    assert_eq!(triangles, 2);
}

fn create_circle(x: f64, y: f64, r: f64, points: usize) -> LineString<f64> {
    let step = 2.0 * PI / ((points - 1) as f64);
    let mut coords = Vec::new();
    for i in 0..points {
        let angle = (i as f64) * step;
        coords.push(Coord {
            x: x + r * angle.cos(),
            y: y + r * angle.sin(),
        });
    }
    LineString::new(coords)
}

#[test]
fn test_overlapping_circles() {
    let mut poly = Polygonizer::new();
    poly.node_input = true;

    // 1. Overlapping Circles
    let c1 = create_circle(30.0, 30.0, 30.0, 100);
    let c2 = create_circle(60.0, 30.0, 30.0, 100);
    let c3 = create_circle(45.0, 55.0, 30.0, 100);

    poly.add_geometry(c1.into());
    poly.add_geometry(c2.into());
    poly.add_geometry(c3.into());

    let polygons = poly.polygonize().unwrap();
    // Expect 8 (7 regions + 1 union).
    assert_eq!(polygons.len(), 8);
}

#[test]
fn test_curved_holes() {
    let mut poly = Polygonizer::new();
    poly.node_input = true;

    // 2. Curved Holes
    let outer = create_circle(50.0, 50.0, 50.0, 200);
    let h1 = create_circle(30.0, 30.0, 10.0, 100);
    let h2 = create_circle(70.0, 30.0, 10.0, 100);
    let h3 = create_circle(50.0, 70.0, 15.0, 100);
    let h4 = create_circle(50.0, 40.0, 5.0, 100);

    poly.add_geometry(outer.into());
    poly.add_geometry(h1.into());
    poly.add_geometry(h2.into());
    poly.add_geometry(h3.into());
    poly.add_geometry(h4.into());

    let polygons = poly.polygonize().unwrap();

    // Expect 5 (Outer + 4 holes).
    assert!(polygons.len() >= 5);
}

```

File: tests/robustness.rs
```
use geo_types::{LineString, Coord, Polygon};
use geo_polygonize::Polygonizer;
use geo::Geometry;

#[test]
fn test_bowtie_noding() {
    // A bowtie shape: (0,0) -> (10,10) -> (10,0) -> (0,10) -> (0,0)
    // Intersection at (5,5).
    let ls = LineString(vec![
        Coord { x: 0.0, y: 0.0 },
        Coord { x: 10.0, y: 10.0 },
        Coord { x: 10.0, y: 0.0 },
        Coord { x: 0.0, y: 10.0 },
        Coord { x: 0.0, y: 0.0 },
    ]);

    let mut poly = Polygonizer::new();
    poly.node_input = true;
    poly.snap_grid_size = 1e-6;
    poly.add_geometry(Geometry::LineString(ls));

    let results = poly.polygonize().expect("Polygonization failed");

    println!("Bowtie Results: {}", results.len());
    for (i, p) in results.iter().enumerate() {
        println!("Poly {}: {:?}", i, p);
    }

    assert_eq!(results.len(), 2, "Expected 2 polygons from bowtie");
}

#[test]
fn test_duplicate_edge_removal() {
    let mut poly = Polygonizer::new();
    poly.node_input = true;
    poly.snap_grid_size = 1e-6;

    // Triangle edge 1
    poly.add_geometry(Geometry::LineString(LineString(vec![
        Coord { x: 0.0, y: 0.0 },
        Coord { x: 10.0, y: 0.0 }
    ])));
    // Duplicate edge 1
    poly.add_geometry(Geometry::LineString(LineString(vec![
        Coord { x: 0.0, y: 0.0 },
        Coord { x: 10.0, y: 0.0 }
    ])));

    // Edge 2
    poly.add_geometry(Geometry::LineString(LineString(vec![
        Coord { x: 10.0, y: 0.0 },
        Coord { x: 5.0, y: 5.0 }
    ])));
    // Edge 3
    poly.add_geometry(Geometry::LineString(LineString(vec![
        Coord { x: 5.0, y: 5.0 },
        Coord { x: 0.0, y: 0.0 }
    ])));

    let results = poly.polygonize().expect("Polygonization failed");
    assert_eq!(results.len(), 1);
}

```

